# UFarm Protocol Architecture

## Overview of the System

The UFarm protocol is composed of a **core contract** (managing global state and permissions) alongside factory contracts for deploying **funds** and **pools**, and per-fund **Fund** contracts with their own **Pool** and **PoolAdmin** sub-contracts. Each Fund acts as a container for one or more investment Pools, and each Pool represents an investable portfolio with its own ERC20 share token. A **PriceOracle** module interfaces with an off-chain oracle network (Quex) to provide asset valuations for Pools. The contracts interact as follows: UFarmCore deploys new UFarmFund instances via FundFactory, funds create Pools via PoolFactory (which spawns a UFarmPool and a corresponding PoolAdmin), and UFarmPools use the PriceOracle for asset pricing and **Protocol Controllers** (external strategy contracts) for interacting with external DeFi protocols.

**Key roles and responsibilities:**

* **UFarmCore (Core):** The central contract governing the system. It maintains global configuration such as whitelisted assets/protocols and protocol-wide parameters (e.g. fees, pause state). It tracks all active funds and ensures only authorized entities can create funds or modify global settings.
* **FundFactory:** A factory contract used exclusively by UFarmCore to deploy new UFarmFund contracts as upgradeable proxy instances. It ensures each fund is linked to UFarmCore and initialized with the proper fund manager.
* **UFarmFund (Fund):** Represents an individual investment fund. Each fund has an owner/manager and a set of authorized staff with various permissions. The fund can spawn Pools (via PoolFactory), and it keeps a registry of its Pools. It also mediates some interactions (like depositing to or withdrawing from a pool on behalf of the fund) and enforces fund-level status (e.g. funds can be *Approved*, *Active*, *Blocked*, *Terminated*) for overall control of operations.
* **PoolFactory:** A factory contract that deploys a new **UFarmPool** (the investment pool contract) together with its **PoolAdmin** companion for any fund that requests a pool creation. Only authorized Fund contracts can call PoolFactory.
* **UFarmPool (Pool):** The core logic for a specific investment pool. It is an ERC20 token contract representing investor shares in the pool and holds the pooled assets. UFarmPool implements deposit and withdrawal mechanics for investors, integrates with external yield/strategy protocols via delegate-calling **Protocol Controller** contracts, and uses the PriceOracle to get up-to-date valuations for its assets. It also handles performance and management fee calculation/accrual.
* **PoolAdmin:** An auxiliary admin contract for each Pool, which holds the configuration (e.g. fee rates, investment limits) and implements privileged actions like starting or stopping the pool. PoolAdmin is controlled by fund managers/staff and interfaces with the Pool to update its state (e.g. changing Pool status) after verifying permissions and conditions.
* **PoolWhitelist (Whitelist logic):** A mix-in contract (inherited by Pool and defined by Core) that enforces that only approved asset tokens and protocol identifiers can be used by the pool. It references the global whitelist maintained in UFarmCore.
* **PriceOracle:** A contract that bridges the on-chain contracts with an off-chain oracle service (“Quex”). It allows authorized users to configure *price feed requests* and enables Pools to query asset prices or portfolio valuations by creating oracle flows and forwarding the results to the requesting Pool.

Below, we describe each contract in detail, including their functionality, internal logic, and interactions with other components or external entities.

## UFarmCore (Core Contract)

**Purpose:** UFarmCore is the central governance contract of the UFarm protocol. It is responsible for managing system-wide settings and registries, including whitelisted assets and protocols, tracking all active funds, and defining global fees and constraints. UFarmCore is also the owner/governor that can pause the entire platform if needed and is the only contract that can directly spawn new funds.

**Key State and Functions:** UFarmCore maintains a list of all fund addresses (`_funds` set) and provides getters like `getFund` and `fundsCount`. It also tracks important global parameters such as `protocolCommission` (the platform’s cut of management fees) and `minimumFundDeposit` (minimum capital a pool must have before it can go live). Critically, UFarmCore includes the **CoreWhitelist** logic to manage which asset tokens and protocol identifiers are allowed system-wide. The core exposes functions like `whitelistTokens` and `blacklistTokens` to modify the allowed asset list and similar functions to whitelist or blacklist protocols by their identifier. Internally, these update an `EnumerableSet` of allowed token addresses and a mapping of token info (including decimals and an identifier for its price feed). UFarmCore ensures that any token added has matching decimals to the provided metadata (reverting with `DecimalsMismatch` if not).

UFarmCore is the owner of two factory contracts, **FundFactory** and **PoolFactory**. During UFarmCore’s initialization, the addresses of these factories (and the PriceOracle) are set and *linked* to the core: the core calls `IUFarmCoreLink.coreCallback()` on each to finalize the binding. This link mechanism designates the core’s address in those contracts (so they recognize UFarmCore as their controller) and likely enables a modifier `onlyLinked` on factory functions, meaning only the known core can trigger certain actions. Indeed, **FundFactory’s** `createFund` method is restricted by `onlyLinked` to be called via UFarmCore. Similarly, **PoolFactory** uses `onlyLinked` combined with an additional check that the caller is a valid Fund. This ensures only an authorized UFarmFund contract (through a call from core or directly) can create new pools.

UFarmCore provides the **function to create new funds**: `createFund(address _fundManager, bytes32 _applicationId)`. Only users with the appropriate permissions (e.g. platform admins with “ApproveFundCreation” rights) can call this. This function calls `fundFactory.createFund(_fundManager, _applicationId)` to deploy a new UFarmFund instance via the FundFactory, then records the new fund address in the `_funds` set and emits a `FundCreated` event. The fund’s manager address (owner) is provided to the factory for initializing the fund.

**Global Whitelist and Controllers:** Through inheriting `CoreWhitelist`, UFarmCore manages `controllers`, a mapping from protocol name (bytes32) to an associated controller contract address. Only protocols present in the whitelist set can be used by pools; if a pool tries an unlisted protocol, it will be blocked (CoreWhitelist’s `_isProtocolWhitelisted` returns false). The core exposes functions to add, update, or remove protocol entries (with events `ProtocolAdded`, `ProtocolUpdated`, `ProtocolRemoved`). Each controller contract contains the logic to interact with a specific external protocol (e.g. Uniswap, Aave) on behalf of pools. UFarmCore’s whitelist ensures only vetted controller contracts can be used. Pools query the core for a protocol’s controller via `IUFarmCore.controllers(protocolId)` and then delegate-call into that controller.

**Permissions and Security:** UFarmCore uses a permissions model (`UFarmPermissionsModel`) to handle roles like the overall platform Owner and various admin capabilities (whitelisting, pausing, etc.). It defines permission masks and includes modifiers (like `ownerOrHaveTwoPermissions`) to restrict critical functions to authorized addresses. For example, only the owner or a combination of a “Member” and a specific admin role can whitelist tokens. The core can also toggle a global pause (`isPaused`) which pool and fund functions respect via checks like `_ufarmIsNotPaused()` in their modifiers. If `isPaused` is true, most state-changing actions in funds/pools will revert with `UFarmIsPaused()`, effectively halting new investments or withdrawals for security emergencies.

In summary, UFarmCore acts as the protocol’s administrator: it creates new funds, keeps the authoritative list of allowed tokens and strategies, defines global fees, and can pause or upgrade components. It communicates with FundFactory/PoolFactory to spin up new contracts, and with PriceOracle to feed it the core address on initialization. All other contracts hold a reference to UFarmCore (directly or via stored `ufarmCore` addresses) to query global settings and ensure their operations comply with the core’s rules.

## FundFactory (Deploys UFarmFund)

**Purpose:** FundFactory is a simple factory contract whose sole job is to deploy new Fund contracts (UFarmFund) for the core. It uses the minimal proxy (Beacon Proxy) pattern so that all Funds share a common implementation but are independent upgradeable proxy instances. This arrangement allows all funds to be upgraded by updating a single beacon’s implementation if needed.

**Relationships:** FundFactory is deployed and initialized with the address of UFarmCore and the address of the **Fund implementation beacon**. During initialization, it calls `__init__UFarmCoreLink(_ufarmCore)` to store the core link, meaning it knows the core’s address and can enforce that only the core calls it. Indeed, `createFund` is guarded by `onlyLinked`, which effectively ties it to UFarmCore’s control.

**createFund Logic:** When UFarmCore wants to create a new fund, it calls FundFactory’s `createFund(address _manager, bytes32 _salt)`. The factory uses a deterministic deployment (`CREATE2`) via a library call `SafeOPS._safeBeaconCreate2Deploy`. This call uses the provided `_salt` (which UFarmCore passes as the fund’s application ID or unique key) to generate a unique proxy address and deploy the beacon proxy pointing to the fund implementation. The `_manager` and core address are passed as initialization data by encoding a call to the fund’s initializer. Specifically, FundFactory prepares the init data with `_getInitFundCall(_manager)`, which encodes a call to `IUFarmFund.__init_UFarmFund(_manager, ufarmCore())`. This ensures the newly deployed UFarmFund is initialized in the same transaction with the given manager address and the core link. The function returns the new fund’s address to the core.

Security-wise, only UFarmCore should trigger fund creation, preventing arbitrary creation of Fund contracts by unauthorized parties. The core will typically only do so for approved applications, maintaining oversight on how many funds exist and who their managers are.

## UFarmFund (Fund Contract)

**Purpose:** UFarmFund represents an individual fund under the UFarm protocol. It is essentially a container for a collection of Pools managed by the same fund manager and team. The Fund contract manages fund-level permissions (who can manage or create pools, etc.), and enforces fund-wide rules such as whether the fund is active or closed. It does **not hold investors’ money directly** (investments go into Pools), but it can act on its Pools and even contribute capital itself (the fund manager’s own capital) to the pools.

**Lifecycle and State:** When a Fund is created via FundFactory, it calls `__init_UFarmFund(_owner, _ufarmCore)` during deployment to set up the fund’s initial state. This sets the fund’s `ufarmCore` reference and assigns full permissions to the `_owner` (fund manager). Each Fund has a `status` state, which can be for example *Pending/Created*, *Approved*, *Active*, *Blocked*, or *Terminated* (the exact enum is `FundStatus`). Initially, a fund might be in a default state (e.g. “Created”). The platform (core) can mark it Approved once due diligence is done, and the fund manager can later activate it. The Fund contract emits events when its status changes. The function `changeStatus(FundStatus newStatus)` allows either the core or the fund owner to change the fund’s status, subject to certain rules. For instance, only the core (UFarmCore) or the fund owner (if aiming to activate or terminate the fund) can change the status, otherwise it reverts with `NonAuthorized`.

UFarmFund also holds an `EnumerableSet` of its Pool addresses and a mapping `isPool[address]` to quickly verify if a given address is one of its pools. This ensures the fund knows which pool contracts belong to it.

**Permission Management:** Each Fund has its own permission system (inheriting UFarmPermissionsModel, similar to core but scoped to fund-level roles). Typical roles include *Fund Owner* (the manager), *Fund Member* (staff), and other roles like *CreatePool*, *ManageFund*, *ManagePoolFunds*, etc., which grant specific capabilities. The fund’s `ownerOrHaveTwoPermissions` modifier is used to protect functions such as creating a pool or managing deposits. This means either the fund’s owner or a staff member with the required two permission bits can perform the action. For example, `createPool` in Fund requires the caller to be a Fund Member and have the “CreatePool” permission, unless they are the fund Owner.

**Creating Pools:** The Fund contract is the only entity that can create new pools for that fund. It provides `createPool(IUFarmPool.CreationSettings memory _settings, bytes32 salt)`, which when called by the fund manager/staff, will in turn call the global PoolFactory’s `createPool` function. The fund first prepares the pool’s settings: it prefixes the pool’s name and token symbol with standardized strings (“UFarm-” and “UF-” respectively) and bundles the core and fund addresses into a `CreationSettingsWithLinks` struct. Then it calls `IPoolFactory(...).createPool(fullSettings, salt)`, passing its core’s PoolFactory address (retrieved from UFarmCore) and a salt. The PoolFactory returns the new pool’s address and its PoolAdmin’s address. The Fund then records the pool by pushing it into its `__poolContracts` list and marking `isPool[pool] = true`, and emits a `PoolCreated` event with details of the new pool (name, symbol, parameters, addresses, etc.). At this point, the pool and pool admin are deployed and initialized (PoolFactory handles calling their `__init` functions), but the pool is in a “Created” status and not yet active.

**Managing Pools:** The Fund contract offers utility functions to interact with its pools on behalf of the fund. For instance, a fund can directly contribute capital to a pool using `depositToPool(address pool, uint256 amount)`. This function ensures the pool belongs to the fund (`_checkPool(pool)`), then uses a SafeERC20 call to approve the pool to pull the tokens from the fund and calls `IUFarmPool(pool).deposit(amount)`. This effectively transfers `amount` of the pool’s base asset from the fund’s own holdings to the pool, where it will be treated like any other deposit (minting pool shares to the fund’s address). The fund might use this to seed a pool with initial capital. The ability to do this is gated by the Fund’s permission modifier (e.g. only fund owner or someone with ManageFund permission). Similarly, a Fund can withdraw from one of its pools via `withdrawFromPool(SignedWithdrawalRequest _request)`, which handles an off-chain signed request scenario (described later) to redeem pool shares back to the fund.

UFarmFund also keeps track of whether it allows use of an **“Arbitrary Controller”** in its pools. This is a special flag that, if true, permits the fund’s pools to utilize a generic/unrestricted controller for investment strategies that are not explicitly whitelisted. The core can set this via `setAllowArbitraryController(fund, bool)` in UFarmCore. The Fund stores this boolean in `_allowArbitraryController[fund]` and provides `isAllowedArbitraryController(fund)`. This setting is referenced in pools when a manager tries to enable arbitrary controllers for a pool.

**Investor Access and Off-Chain Requests:** Note that investors (external EOA users) typically do **not** interact with the UFarmFund contract directly; instead, they invest in specific pools (which are ERC20 vaults). However, UFarmFund supports an *invitation and signature* mechanism for adding fund members and processing deposits/withdrawals via signed messages. The fund has mappings like `__acceptedInvites` and uses `ECDSARecover` library to verify signatures. In particular, functions `validateDepositRequest` and `validateWithdrawalRequest` in UFarmPool (or possibly the fund) allow the contract to validate a user-signed intent to deposit/withdraw without the user calling the function themselves. This could allow a backend or fund manager to bundle transactions on behalf of users. The fund’s events `InvitationAccepted` etc. suggest that a Fund manager can invite staff who then accept via signed message, although those details are beyond core architecture.

**Dependencies:** Each UFarmFund stores references to UFarmCore (`ufarmCore`), its PoolFactory (via core) and PriceOracle (via core), and of course its Pools. It uses the core link for checking global state like `isPaused` or calling core for certain info. For example, Fund functions often begin with `ufarmIsNotPaused` modifier to ensure the core hasn’t paused the platform. They also check the fund’s status for operations (using `poolManagementAllowed` or `requiredStatus` modifiers) – e.g. you can only create pools if the fund is in Approved or Active status, not if it’s closed.

In summary, UFarmFund is a managerial layer: it is created by the core with a designated owner, it can spawn multiple pools, and it coordinates those pools. It does not perform any complex financial logic itself; instead, it delegates that to pools. Its main concerns are **permission control**, **pool lifecycle (creation/recording)**, and enforcing **fund-wide constraints** (like whether the fund as a whole is active or not). Security-wise, it ensures only authorized persons can create pools or change fund settings, and that only valid pools can be interacted with through the fund.

## PoolFactory (Deploys UFarmPool and PoolAdmin)

**Purpose:** PoolFactory creates new pools for a given Fund. It is called by a Fund contract when a fund manager wants to open a new investment pool. Just like FundFactory, PoolFactory uses upgradeable beacon proxies for pool contracts. In fact, it manages two beacons: one for the UFarmPool implementation and another for the PoolAdmin implementation. Every pool in the system is a proxy pointing to the shared Pool logic contract, and every pool admin is a proxy pointing to a shared PoolAdmin logic contract. This allows pool behavior to be upgraded platform-wide if necessary.

**Access Control:** PoolFactory is linked to UFarmCore (set in its constructor similarly to FundFactory), and its `createPool` method is also marked `onlyLinked`. In practice, UFarmFund contracts call this function, not the core directly. To ensure only legitimate funds can create pools, the PoolFactory additionally checks `if (!IUFarmCore(ufarmCore()).isFund(msg.sender)) revert CallerIsNotFund();`. This means even though any address could call PoolFactory’s function, it will reject calls where `msg.sender` is not recognized by UFarmCore as one of its registered funds. This double-lock (core link + isFund check) guarantees that only real UFarmFund contracts tied to the core can spawn pools.

**Pool Creation Flow:** When `createPool(CreationSettingsWithLinks calldata _settings, bytes32 salt)` is invoked by a Fund, the PoolFactory will deploy two new proxies:

1. A PoolAdmin proxy, using the provided salt.
2. A UFarmPool proxy, using the same salt.

It uses the internal addresses `poolAdminImplBeacon` and `poolImplementationBeacon` for the templates. The deployment is done with `SafeOPS._safeBeaconCreate2Deploy`, similar to FundFactory, to ensure unique addresses. By using the same salt for both deployments and different beacon addresses, PoolFactory ensures each Pool and its PoolAdmin have a known deterministic address (given fund and salt), without clashing since the beacon contract address is part of the create2 deterministic address calculation.

After deploying the proxies (still uninitialized), PoolFactory calls the initialization functions on both:

* `IPoolAdmin(poolAdmin).__init_PoolAdmin(_settings, pool)` to initialize the PoolAdmin.
* `IUFarmPool(pool).__init_UFarmPool(_settings, poolAdmin)` to initialize the Pool.

These calls pass in the creation settings (which include the pool’s name, symbol, fee configuration, and references to the fund and core) and link each contract to the other’s address. By the end of `createPool`, the two new contracts know about each other and about their fund/core.

The PoolFactory returns the addresses `(pool, poolAdmin)` to the caller, which in this case is the Fund’s `createPool` function. The Fund then records them and emits its event as described earlier.

**PoolFactory’s getPoolBySalt:** The factory also provides a view function `getPoolBySalt(bytes32 salt) returns (address pool, address poolAdmin)`. Given a salt (and implicitly the context of the caller fund, since each fund likely uses its own PoolFactory instance or the core knows how to derive address), it computes what addresses the pool and admin *would* have if deployed. It uses the same deterministic formula via `SafeOPS.computeBeaconProxyAddress` with the stored beacon addresses and init data (which in this case is empty for deployment, since initialization is done after). This can be used to check if a particular pool already exists or to pre-compute addresses (the fund might call this to avoid duplicate pool creation with the same salt).

Overall, PoolFactory is a straightforward factory with minimal logic aside from orchestrating the double-deployment and calling initializers. The heavy lifting of initialization is done in PoolAdmin and UFarmPool contracts. PoolFactory trusts UFarmCore’s registry for security and does not impose additional business rules (those are handled in the Fund and PoolAdmin/Pool code).

*By isolating fund creation and pool creation in separate factory contracts, UFarm’s design adheres to the upgradeable proxy pattern and clean separation of deployment rights.* Only the core can create funds, and only funds can create pools, ensuring a controlled hierarchy.

## PoolAdmin (Pool Administration Contract)

**Purpose:** Each Pool has a dedicated PoolAdmin contract that handles administrative tasks and configuration for that pool. The PoolAdmin essentially acts as the governance module of the pool, separate from the vault logic. This includes managing the pool’s fee rates, investment limits, lock-up periods, and controlling the pool’s lifecycle (e.g., moving it from *Created* to *Active* to *Terminated* status in coordination with the Pool contract). It also maintains the list of addresses with permissions on the pool (pool-level “staff”), separate from the fund’s own permission list (though there is interplay between fund and pool permissions as described below).

**Initialization:** When PoolFactory deploys a new PoolAdmin proxy, it calls `__init_PoolAdmin(CreationSettingsWithLinks _settings, address poolAddr)` on it. Inside this initializer, PoolAdmin sets up the pool’s initial configuration and permissioning:

* It iterates over the list of initial staff provided in `_settings.params.staff` (an array of addresses and their permission masks) and calls `_updatePermissions(staff.addr, staff.permissionsMask)` for each. This populates the internal permission bitmap for pool members (using UFarmPermissionsModel’s logic) so that the fund manager and any other designated addresses have the rights specified (e.g. permission to manage investments, etc.) from the start.
* It then stores references to the related contracts: `ufarmFund`, `ufarmCore`, and `ufarmPool` are all saved (these come from the \_settings links and the parameter). This ties the PoolAdmin to the fund, the core, and its pool.
* Next, it initializes the **PoolConfig** struct with the provided parameters: management fee, performance fee structure, min/max investment, and withdrawal lockup period. Before setting, it validates that the provided values are within allowed ranges: management fee is between 0 and 10% (TEN\_PERCENTS constant), lockup period is not more than `MAX_LOCKUP_PERIOD` (100 days), and minInvestment is <= maxInvestment (checked by `_checkInvestmentBorders`). Performance fee is provided as a packed uint256 representing tiers; the initializer “packs” it again via `packPerformanceCommission()` presumably to validate the structure and store it consistently. After this, `poolConfig` is set with the validated values.

After initialization, the PoolAdmin emits events if needed (none in init, but later when changes happen). The pool’s initial status remains `Created` (actually set on the pool side during its init), meaning the pool isn’t active until explicitly started.

**Relationship with UFarmPool:** The PoolAdmin and UFarmPool work in tandem. PoolAdmin has the authority to invoke the Pool’s `changeStatus` function and to adjust parameters that the Pool will use (like fees). Meanwhile, the Pool will consult PoolAdmin for permission checks. For example, PoolAdmin has a function `isAbleToManageFunds(address manager) view returns (bool)` that checks if the given address has the rights to manage the pool’s investments. It does this by ensuring the fund is active (`_checkActiveFund()`) and then verifying either the manager has Pool-level permissions (Pool.Member + Pool.ManagePoolFunds) or has the Fund-level permission to manage all pools. It returns true if authorized, otherwise reverts with `NonAuthorized`. The UFarmPool contract calls this `IPoolAdmin.isAbleToManageFunds(msg.sender)` as a gating check before allowing certain actions (like protocol investments). This design means a fund-level manager with a global role can manage any pool of the fund, even if not explicitly listed in pool’s staff, and conversely a pool-specific manager (in PoolAdmin’s list) can manage that pool even without global fund permissions — as long as the fund is active.

**Pool Lifecycle Control:** One of PoolAdmin’s critical functions is `changePoolStatus(IUFarmPool.PoolStatus _newStatus)` (called by fund managers to start or terminate the pool). This function enforces all the rules around transitioning a pool’s state:

* It ensures the caller is a fund member (`onlyFundMember`) and the fund itself is active (`onlyActiveFund`) (you cannot change pool status if the fund is not active).
* It requires the caller to have either Pool-level or Fund-level PoolStatusControl permission.
* It then retrieves the current pool status from the Pool contract (`currentPoolState = IUFarmPool(ufarmPool).status()`).
* Various checks are applied: the new status cannot be the same as current (no redundant changes); if the current status is Terminated, no further changes allowed; you cannot “reverse” status (e.g., set to a status less mature than current) – specifically, Active is the earliest non-created state and \_newStatus must not be less than Active once the pool is running.
* To activate a pool (\_newStatus == Active), PoolAdmin ensures the pool is currently in Created state and then checks if the pool has at least the minimum required capital: it calls `IUFarmPool(ufarmPool).getTotalCost()` (the pool’s total asset value) and compares it with `IUFarmCore(ufarmCore).minimumFundDeposit()`. If the total assets are below the global minimum, it reverts `InsufficientDepositAmount`. This guarantees that a pool cannot be activated unless it’s funded with a minimum amount (ensuring seriousness and covering initial fees).
* If the new status requested is “Deactivating” (an intermediate state before Termination), it requires that the current state is Active (only active pools can start deactivation). If the new status is “Terminated”, it will allow that from Created, Active, or Deactivating states but not from an already terminated pool (handled by earlier checks). Before terminating, the PoolAdmin sets the pool’s withdrawal lockup period to 0 (no lockup), effectively lifting any remaining withdrawal restriction to allow final withdrawals.

After all checks, PoolAdmin calls `IUFarmPool(ufarmPool).changeStatus(_newStatus)` to actually update the pool’s status on the pool contract. The Pool contract’s `changeStatus` function is restricted to only allow calls from its PoolAdmin, so this call will succeed in changing the state and emitting the Pool’s `PoolStatusChanged` event internally. (PoolAdmin itself may not emit an event for status change beyond forwarding the call.)

**Fee and Config Management:** PoolAdmin has functions to update the pool’s fee parameters and limits, all guarded by appropriate permissions and only allowed in certain pool states (usually before the pool is Active, i.e., while `status == Created`). For example:

* `setCommissions(uint256 managementCommission, uint256 packedPerformanceFee)` updates the management fee and performance fee structure. It requires `onlyFundMember`, `onlyActiveFund`, and pool status *Created* (so fees can only be adjusted before the pool starts). It also checks the caller has permission (Pool.UpdatePoolFees or Fund.UpdatePoolFees). The function then compares the new values with current ones, and if there’s no change it reverts `ActionAlreadyDone` to prevent redundant transactions. If there are changes, it validates the new performance fee steps by unpacking and repacking them (ensuring they are within the allowed count and values) and ensures the management fee is within 0–10% range (via `valueInRange` modifier or internal check). Finally it updates the `poolConfig` with the new values and emits a `CommissionChanged` event.
* `setLockupPeriod(uint128 newPeriod)` sets a new withdrawal lockup period (the time an investor must wait after requesting withdrawal). It’s also restricted to status Created (cannot change after activation) and appropriate permission. It reverts if the new period is the same as current, checks that `newPeriod <= MAX_LOCKUP_PERIOD`, then updates the config and emits `LockupPeriodChanged`.
* `setInvestmentRange(uint256 minInvest, uint256 maxInvest)` updates the minimum and maximum allowable investment amounts for the pool. This can be called even when the pool is Active (since adjusting investment limits during operation might be allowed) but not after the pool is Deactivating/Terminated. The code explicitly prevents changing the range if the pool has already passed the Active state: if current status > Active, it reverts `InvalidPoolStatus` (only Active or Created allowed). It requires permission (Pool.UpdatePoolTopUpAmount or Fund.UpdatePoolTopUpAmount). If values are actually changed, it sets the new min and max and emits `InvestmentRangeChanged`.

These functions ensure that pool parameters can be tuned by the fund manager before the pool launches, but once the pool is active, most of them become read-only (except investment range, which can be adjusted within limits, and certain fee aspects if perhaps allowed by design after periods, though in this implementation performance fee structure is locked at start).

All config changes pass through PoolAdmin, meaning UFarmPool itself never allows arbitrary changes to these critical values except via its PoolAdmin.

**Permissions Architecture:** PoolAdmin inherits `UFarmPermissionsModel`, so it manages a mapping of account -> permission bits for pool-specific roles. It uses helper functions `_hasPermissionMask` and `_twoPermissionsToMask` (inherited) to check combined permissions. It also defines a utility `checkPoolOrFundPermission(address account, Permissions.Pool poolPerm, Permissions.Fund fundPerm)`, which it uses to streamline checks where either a pool-level or fund-level permission suffices. This function is used in many of the external functions described above (e.g., updating fees or lockup) to allow either role to proceed. If the account is not at least a Pool member with that pool permission and also doesn’t have the fund-level permission, it reverts `NonAuthorized`.

**Interaction with Core (UFarmCore):** PoolAdmin calls UFarmCore for two main purposes: (1) to check the global pause status (`_ufarmIsNotPaused()` uses `IUFarmCore(ufarmCore).isPaused()` and reverts if true), and (2) to retrieve the global minimumFundDeposit when needed (though typically the Pool contract itself does that for activation check as we saw). It doesn’t directly modify core state but respects it.

**Interaction with Fund (UFarmFund):** PoolAdmin frequently ensures the fund is in the right status via `_checkActiveFund()`, which fetches `IUFarmFund(ufarmFund).status()` and requires it to be Active, otherwise `WrongFundStatus` error. This prevents pool operations (like starting the pool or managing it) if the fund has not been marked active or if it’s blocked/terminated by core. This provides a layer of control from core -> fund -> pool: if core or fund sets the fund to a non-active state, PoolAdmin will reject many operations, effectively freezing the pool’s management (though investors might still withdraw depending on conditions).

In summary, PoolAdmin is the *control tower* for a pool. It ensures only the right people can perform admin actions, it enforces platform rules when those actions are attempted, and it updates the pool’s state accordingly. For auditors, a key point is that PoolAdmin is the only entity that can change a pool’s status and critical parameters — the Pool contract delegates these responsibilities to PoolAdmin to maintain a clear separation of privilege. All calls from PoolAdmin to Pool (like changing status) are single-step and emit events, making it easier to track in logs. Conversely, the Pool will call back to PoolAdmin for permission checks or to retrieve config (e.g., Pool might call `IPoolAdmin(poolAdmin).getConfig()` to read the latest commission and limits).

## UFarmPool (Pool Contract)

**Purpose:** UFarmPool is the contract that holds and invests user funds — effectively the vault for a specific strategy under a fund. Each UFarmPool is an ERC20 token (inheriting OpenZeppelin ERC20Upgradeable) representing shares of the pool. Users deposit a specific base asset (the “value token” of the pool, e.g. USDC or ETH) and receive pool shares; later they can withdraw to redeem shares for the underlying asset value. The pool’s logic handles accepting deposits, queuing and processing withdrawals (with optional lockup), investing and divesting assets through protocol controllers, and calculating fees. It interacts with the PriceOracle to get the latest valuation of its holdings, especially when processing deposits/withdrawals to ensure correct share pricing.

**Core State Variables:** Key state includes:

* `address ufarmFund; address private _ufarmCore; address public poolAdmin; address public valueToken;` – references to the parent fund, core, the pool’s admin contract, and the asset this pool accepts.

* `PoolStatus public status;` – the current lifecycle status of the pool (an enum with at least values: Created, Active, Deactivating, Terminated, etc.).

* `uint256 public highWaterMark; uint256 public lastAccrual;` – used for performance fee calculation (highWaterMark tracks the highest historical total value attained, and lastAccrual is the timestamp when fees were last accrued).

* Internal accounting for pending operations: The pool maintains two **queues** for asynchronous operations:

  * `depositQueue` (array of `QueueItem`) to hold pending deposits.
  * `withdrawQueue` (array of `QueueItem`) for pending withdrawals.

  A `QueueItem` likely contains at least `{address investor; uint256 amount; bytes32 requestHash}` representing either an investor’s deposit amount or shares-to-burn for withdrawal, plus an optional hash if the request was initiated via an off-chain signed message. Indeed, we see `depositQueue.push(QueueItem(amount, 0, msg.sender))` when a direct deposit happens, and for withdrawals via signature, a hash is included.

* Mappings like `__usedDepositsRequests` and `pendingWithdrawalsRequests` to track which off-chain requests have been fulfilled or are waiting for lockup. This prevents replaying the same signed message and handles lockup timing.

* `bool private __isManagerAction;` – a flag used internally to differentiate whether a protocol operation is initiated by a manager or not. It’s set to `true` in `protocolAction` calls and presumably read by controller functions to allow certain privileged actions when true.

* Temporary state used during delegatecalls: `bytes32 public protocolInUse; address public _protocolTarget;` (not shown above but inferred from `_protocolAction` storing them). These are used to store context for the controller call (which protocol is being used and what address to treat as target in that call).

**Deposit Workflow:** Users (investors) can deposit into the pool by calling `deposit(uint256 _amountToInvest)`. Key points in this function:

* It checks the platform and fund are not paused (modifier `ufarmIsNotPaused`) and `_amountToInvest` is non-zero.
* `_checkStatusForFinancing(true)` is called to ensure deposits are allowed in the current state. This internal function distinguishes fund and investor cases:

  * If `msg.sender` is the fund itself, it allows deposit only if fund status ≤ Active and pool status is before or at Deactivating (so the fund can add capital even during Active, but not after pool is Terminated).
  * If `msg.sender` is a normal investor, it requires the fund status to be Active and the pool status to be Active (investors can only deposit when the fund is active and the pool is active).
* It fetches the pool’s current min and max investment limits from PoolAdmin (`getConfig()` returns the PoolConfig), then if the depositor is not the fund, it ensures `_amountToInvest` lies between `minInvestment` and `maxInvestment`. If outside range, it reverts `InvalidInvestmentAmount`.
* Instead of immediately transferring tokens and minting shares, the deposit is **queued**: `depositQueue.push(QueueItem(_amountToInvest, bytes32(0), msg.sender))`. The requestHash is zero here indicating a direct call (no off-chain request).
* After queuing, it calls `sendQuexRequest()`.

This design implies deposits are processed asynchronously via the oracle. The pool likely uses the PriceOracle to fetch the latest total value of the pool (including any deployed capital in strategies) before minting new shares, to ensure the incoming deposit is priced correctly relative to the pool’s Net Asset Value. By pushing to a queue and then triggering an oracle request, the pool defers actual minting until the oracle responds with an updated valuation.

**Withdraw Workflow:** Similarly, for withdrawals, UFarmPool offers `withdraw(SignedWithdrawalRequest calldata _withdrawalRequest)` for investors. If the fund itself calls withdraw (meaning the fund manager wants to pull out the fund’s own capital), the code path is slightly different:

* If `msg.sender == ufarmFund` (the fund contract), it doesn’t require a signature. It simply creates a QueueItem with `sharesToBurn = _withdrawalRequest.body.sharesToBurn` and a unique hash (computed from current block hash and totalSupply as salt). This is presumably to have a request identifier for internal tracking. It then pushes to `withdrawQueue` with that hash and the fund’s address.

* If `msg.sender` is not the fund (an external investor), the function uses `validateWithdrawalRequest(_withdrawalRequest)` to recover the investor’s address and shares to burn from the signature. It ensures the signature is valid and not expired or already used. This yields `(investor, sharesToBurn, withdrawalRequestHash)`. It then checks the pool’s lockup configuration:

  * If `withdrawalLockupPeriod > 0`, it uses a mapping `pendingWithdrawalsRequests` to enforce the delay. If this is the first time seeing this `withdrawalRequestHash`, it stores the current timestamp and emits a `WithdrawRequestReceived` event. Then it returns without actually queuing the withdrawal (the user must call `withdraw` again after the lockup period).
  * If the user calls again after the lockup period, the code finds an entry in `pendingWithdrawalsRequests` and checks if `now >= requestedTime + lockupPeriod`. If the period hasn’t passed, it reverts `LockupPeriodNotPassed`. If the period passed, it proceeds to initiate pool shutdown: it calls `_changeStatus(PoolStatus.Deactivating)` on the pool itself and returns, *not* queueing the withdrawal yet. This design means the first user to withdraw after lockup expiration triggers the pool to start the *Deactivating* phase (preventing new investments and signaling managers to prepare for closure). The actual withdrawal will be queued on a subsequent call or by the fund manager once assets are ready.
  * If lockup period is zero (no delay required), or after setting pool to Deactivating (the next step presumably), it goes ahead and pushes `withdrawQueue.push(QueueItem(sharesToBurn, withdrawalRequestHash, investor))`.

* Finally, if a withdrawal was queued (in either branch), it calls `sendQuexRequest()` similar to deposit.

This logic means normal user withdrawals are a two-step process if a lockup is set: request (which logs and requires waiting) and then finalize (which might start deactivation). If no lockup, it directly queues. The pool uses the PriceOracle after queuing to get the latest valuation for processing.

**Oracle Interaction (PriceOracle and Quex):** The function `sendQuexRequest()` is used by both deposit and withdraw flows. It prepares and triggers the oracle update if one isn’t already in progress:

* It checks if `requestId == 0` (meaning no oracle request is currently outstanding). If a prior request is still pending (i.e., the pool is mid-processing a previous batch of operations), it will not send a new request, so multiple deposits/withdrawals can queue up and be processed in one batch once the current oracle response arrives.
* If no request active, it obtains the `IQuexOracle` interface for the PriceOracle (via core’s stored address). It likely has stored a `quexFlowId` which identifies the kind of data it needs (for example, a flow that calculates the total USD value of all pool assets). The code then calls `requestId = quexOracle.quexRequest{value: gasCost}(quexFlowId)`. Here `gasCost` is presumably an amount of ETH the pool has set aside to pay the oracle fees (in the code, it transfers any remaining balance back to the fund after the call). The PriceOracle’s `quexRequest` forwards this call to the Quex Action Registry, and returns a `requestId` for tracking. PriceOracle immediately refunds any excess ETH back to the caller (pool), but the pool then sends that refund to the fund (`payable(ufarmFund).transfer(address(this).balance)`) to ensure the pool itself doesn’t keep leftover ETH (likely the fund is considered the owner of any spare).
* The `requestId` (a uint256) is stored in the pool’s state to mark an outstanding oracle query.

At this point, the deposit/withdraw function ends. The actual transfer of tokens and minting/burning of shares will occur after the oracle responds.

**Oracle Callback:** The PriceOracle, after getting data from the off-chain network, will callback to the UFarmPool’s `quexCallback(uint256 receivedRequestId, DataItem memory response)` function (UFarmPool implements `IQuexOracleReceiver`). In `quexCallback`:

* It first validates that `msg.sender` is the expected Quex oracle core (PriceOracle gets the `quexCore` address, which the off-chain system uses to make callbacks). If the call is not from the authorized oracle, it reverts `InvalidQuexCore`.

* It then checks that `receivedRequestId == requestId` that it had stored. If not matching, it reverts `InvalidQuexRequestId` (preventing stale or unknown callbacks).

* With the correct response, it resets `requestId` later (once processing done) and proceeds to use the oracle data. The `DataItem response` likely contains the aggregated total value of the pool’s assets (perhaps in the same denomination as valueToken or in a fixed reference currency). The code does `_totalCost = abi.decode(response.value, (uint256))` to extract a uint256 value. This represents the pool’s updated total asset value (the sum of all holdings in valueToken terms). This figure is used to price deposits and withdrawals.

* It then retrieves the pool’s fee settings via PoolAdmin: `config = IPoolAdmin(poolAdmin).getConfig()` to get the current managementCommission and packedPerformanceFee (and possibly other fields). With these, it calls `_accrueFee(_totalCost, config.managementCommission, config.packedPerformanceFee)`. This internal function calculates any accumulated management or performance fees since the last accrual and mints new pool shares to the fund and platform (core) as needed:

  * If this is the first time (lastAccrual == 0), it sets the initial highWaterMark and lastAccrual and returns.
  * Otherwise, it computes the fees: it uses `accrualTime = now - lastAccrual` and multiplies the pool’s average value over that period (approximated by `totalCost * time / YEAR`) by the respective commission rates to get the absolute fee amounts. The global protocol commission is fetched from core and applied to yield `protocolFee`, while the managementCommission from config yields `managementFee`.
  * It then calculates performanceFee if the new total cost exceeds the highWaterMark (meaning profit): profit = totalCost - highWaterMark, then computes a fee based on the configured performance fee schedule. The performance fee schedule is stored in a packed form with tiers; the code unpacks it to find the appropriate fee % for the profit level, then calculates `performanceFee` amount.
  * It splits the fees between fund manager and platform: typically, the platform might take 20% of the combined performance+management fees (this appears to be the case: they compute `totalFundFee` = 80% of (performanceFee+managementFee), and `totalUFarmFee` = 20% of (performanceFee+managementFee) + protocolFee). The `protocolFee` (from core’s rate) is added on top for the platform.
  * It then determines how many new shares correspond to these fee amounts: it calls `_sharesByQuote(value, totalSupply, totalCost)` which essentially does `shares = (value * totalSupply) / totalCost` (the proportion of the pool’s current supply that equals that value). For platform fees, it calculates `sharesToUFarm` for `totalUFarmFee`, and for fund fees, `sharesToFund` for `totalFundFee` (note: it adds `sharesToUFarm` to supply before calculating fund’s portion to properly account for dilution).
  * Finally, it mints `sharesToUFarm` to `_ufarmCore` (the core contract address) and `sharesToFund` to `ufarmFund` (the fund address) by calling `_mintShares()`. Any non-zero mint will update `lastAccrual = now` and emit `FeeAccrued(protocolFee, managementFee, performanceFee, sharesToUFarm, sharesToFund)`. This effectively transfers the calculated fee value from the pool to the platform and fund in the form of newly issued shares (diluting other investors slightly to pay fees). The `highWaterMark` is updated to the new total cost if it was exceeded.

* After accruing fees, the `_totalCost` now represents the post-fee value of the pool (since fees were accounted by minting shares, but importantly, the underlying value in the pool hasn’t changed; instead the ownership distribution changed. The pool’s total value is still `_totalCost`). Now the contract processes queued **Deposits** and **Withdrawals** in turn:

  * **Processing Deposits:** It iterates while `depositQueue` is not empty. For each queued deposit (starting from the most recent or last pushed entry as written), it takes `amountToInvest` and `investor` from the queue item. It tries to execute `this.safeTransferToPool(investor, amountToInvest)` inside a try-catch. `safeTransferToPool` is likely an internal function (possibly generated by SafeOPS library or implemented to perform `IERC20(valueToken).safeTransferFrom(investor, address(this), amount)`). Because it’s called via `this.` and inside try, it suggests it’s public and uses `msg.sender` internally to actually do the transfer. If the transfer fails (for instance, if the investor didn’t approve the pool or has insufficient balance), the catch will trigger: the code then pops that deposit from the queue without minting shares (effectively skipping it), and continues to the next deposit. This way, failed deposit attempts don’t block the queue indefinitely.

    * If the transfer succeeds, the pool now holds the deposit amount in its contract balance. It then calculates how many shares to mint for this deposit: `sharesToMint = _mintSharesByQuote(investor, amountToInvest, _totalCost)`. `_mintSharesByQuote` will compute `shares = (amountToInvest * totalSupply) / _totalCost` if the pool already had a supply (i.e. existing investors), or simply `shares = amountToInvest` if the pool was empty. It then mints that many new shares to the investor. This formula ensures the investor’s share of the pool is proportional to their contribution relative to pool value (using the latest value \_totalCost which includes the value *before* this deposit was added). After minting shares, the code updates `_totalCost += amountToInvest` and also tracks `totalDeposit += amountToInvest` for later. This increment of \_totalCost assumes the deposit’s cash simply increases pool value linearly (which is true since before investing it’s just added cash).
    * It emits a `Deposit` event with investor, token, amount, and shares minted.
    * If the deposit was initiated via an off-chain request (indicated by a non-zero `depositRequestHash` in the QueueItem), it marks that request as used: `__usedDepositsRequests[hash] = true` and emits `DepositRequestExecuted`. (For direct deposits, the hash is zero and this is skipped.)
    * It then pops the processed deposit from the queue and continues until all deposits in the queue are handled.
    * After finishing deposits, it updates `highWaterMark += totalDeposit`. This is interesting: because they treat any new deposit as raising the highWaterMark baseline by the deposit amount, ensuring that subsequent performance fee calculations only consider profit above the contributed capital. This prevents charging performance fees on new deposits (which are not profit but new principal).

  * **Processing Withdrawals:** Next, it processes the `withdrawQueue` similarly in a loop. For each withdrawal request:

    * It retrieves `sharesToBurn` and `investor` (and any `withdrawalRequestHash`).
    * It calculates `availableToWithdraw` which is the maximum shares that can be withdrawn by that investor under current constraints. If the `investor == ufarmFund` (the fund itself), it enforces the **mandatory minimum** share retention if the pool is still active: The code computes `valueTokensToRemain` – which is:

      * If pool status is still Active (< Deactivating), `valueTokensToRemain = core.minimumFundDeposit()` (the platform’s minimum capital requirement).
      * If pool status is Deactivating or Terminated, `valueTokensToRemain = _totalCost - IERC20(valueToken).balanceOf(address(this))`. This likely represents the portion of assets still deployed in external protocols (since `_totalCost` is total value, and `balanceOf(this)` is what’s currently in the contract; the difference is presumably still invested elsewhere). They require that amount to remain covered by the fund until those external assets are recovered.
        Then it computes `mandatoryShares = (valueTokensToRemain * totalSupply()) / _totalCost` – the number of shares corresponding to the mandatory remaining value (this is how many shares must stay unredeemed to still represent valueTokensToRemain in the pool). It gets the fund’s current share balance `totalUserShares = balanceOf(ufarmFund)`. Then:
        `availableToWithdraw = totalUserShares > mandatoryShares ? totalUserShares - mandatoryShares : 0`. So if the fund is trying to withdraw and the amount of shares it wants to burn would drop its shareholding below the required minimum, the excess beyond what’s allowed is clamped. Essentially, the fund cannot withdraw below the required minimum value (to keep the pool operational or to cover outstanding investments).
    * If `investor` is not the fund, `availableToWithdraw = balanceOf(investor)` (all their shares can be withdrawn), since no special restriction for normal investors beyond their own balance.
    * Now if `sharesToBurn > availableToWithdraw`, it means the request is asking to burn more shares than allowed. The code then deletes `pendingWithdrawalsRequests[hash]` (if any) and pops the queue item without processing – effectively skipping this withdrawal because it’s invalid or exceeds limits.
    * If it’s within allowed range, it proceeds to process: it calls `_processWithdrawal(investor, sharesToBurn, _totalCost, withdrawalRequestHash)`. This function will burn the shares and attempt to transfer the corresponding value tokens to the investor:

      * It calculates `burnedAssetsCost = (_totalCost * sharesToBurn) / totalSupply` – the pro-rata value of those shares. Then:
      * If the pool’s contract has at least `burnedAssetsCost` of the valueToken on hand (`balanceOf(this) >= burnedAssetsCost`), it executes the withdrawal: `_burn(investor, sharesToBurn)` burns the shares, then `IERC20(valueToken).safeTransfer(investor, burnedAssetsCost)` sends the assets. An event `Withdraw(investor, token, burnedAssetsCost, requestHash)` is emitted. It also reduces `highWaterMark` by the amount withdrawn (but not below 0), ensuring profit calculation accounts for this outflow. It marks the withdraw request as executed (emitting `WithdrawRequestExecuted(investor, sharesToBurn, requestHash)`).
      * If the contract does not have enough balance to cover `burnedAssetsCost`, it means some assets are still invested externally and cannot be immediately withdrawn. In this case, the function sets `burnedAssetsCost = 0` and returns 0 without burning shares. (No event is emitted in this branch, meaning the withdrawal isn’t completed yet.)
      * It returns the `amountToWithdraw` (which is equal to burnedAssetsCost if successful, or 0 if not).
    * Back in the loop, they capture `amountToWithdraw`. If `investor != ufarmFund` (meaning a regular investor) and `amountToWithdraw != 0` (meaning the withdrawal was executed fully), they mark the withdraw request as used (`__usedWithdrawalsRequests[hash] = true`) and delete it from `pendingWithdrawalsRequests` mapping. (For fund withdrawals or if nothing withdrawn, they don’t mark anything here.)
    * They then update `_totalCost -= amountToWithdraw` (reduce the pool’s recorded value by the amount that left). If `amountToWithdraw` was 0 (meaning the withdraw couldn’t be completed now), \_totalCost remains counting those assets as still in pool – which is correct, since they are still invested out there.
    * Finally, they pop the withdrawal from the queue and continue to next.

  * After processing all queued withdrawals, the function sets `requestId = 0` to mark that the oracle request cycle is complete and the pool is ready to accept a new `sendQuexRequest` next time. The entire deposit/withdraw cycle triggered by that one oracle callback is done.

**Investing via Protocol Controllers:** Beyond deposit and withdrawal, UFarmPool allows fund managers to actually invest the pool’s assets into various strategies. This is done via the `protocolAction(bytes32 _protocol, bytes calldata _data)` function. This function is restricted with `onlyFundMember` and `nonReentrant` and requires the platform not paused. It performs:

* `_checkProtocolAllowance(_protocol)` which uses PoolWhitelist to ensure the protocol is whitelisted (or the pool is allowed arbitrary controllers). If not allowed, it reverts `ProtocolNotAllowed`.
* `_statusBeforeOrThis(PoolStatus.Deactivating)` to ensure the pool’s status is not beyond Deactivating. In other words, you can call `protocolAction` when the pool is Active or even Deactivating (perhaps to unwind positions during deactivation), but not if it’s already Terminated.
* `IPoolAdmin(poolAdmin).isAbleToManageFunds(msg.sender)` to ensure the caller has permission (either pool-level or fund-level as discussed). If not, it reverts inside that call.
* It then sets `__isMangerAction = true` (note the spelling is likely a typo in code, should be Manager).
* Calls `_protocolAction(false, _getProtocolController(_protocol), _protocol, address(this), _data)`.
* Finally `delete __isMangerAction` (resets the flag).

The `_getProtocolController` looks up the controller address from UFarmCore’s mapping and `_protocolAction` performs a `delegatecall` into that controller contract in the context of the pool. It sets `protocolInUse` and `_protocolTarget` before the call, and clears them after. This likely allows the controller’s code to know which protocol identifier is being handled and use `_protocolTarget` (which is set to `address(this)` for manager actions, i.e., the pool itself) as needed. If `_ignoreRevert` (first parameter) were true, it might catch and continue on revert, but here it’s false for manager-called actions so any failure in the controller call will bubble up and revert the transaction, ensuring unsuccessful actions don’t accidentally get marked as successful.

When a controller executes via delegatecall, it runs with full access to the pool’s storage. The controller can transfer tokens from the pool, enter external contracts, etc. To maintain safety:

* Controllers should check `protocolInUse` and perhaps `__isManagerAction` flags to ensure calls come through the intended path (for example, a controller might allow investor-initiated actions only if `__isManagerAction` is false).
* The pool sets `_protocolTarget = address(this)` for manager actions. Interestingly, if there were an investor-facing action, the pool might set `_protocolTarget = msg.sender` to limit what target address can be affected (this pattern is often used to protect delegatecalls). However, in the code provided, `protocolAction` always uses `address(this)` as target. Possibly, if there were investor-driven protocol actions (not present in this design), they might have another function that calls `_protocolAction(true, controllerAddr, protocol, msg.sender, data)` to allow some limited usage by investors (for example, if investors could deposit specific assets into the pool or claim something). But none is explicitly seen, so `protocolAction` is primarily for managers.

After delegatecall, it emits `SuccessfulControllerCall(_protocolHash)`. The actual effect of the call depends on the controller logic: e.g., a controller for a lending protocol might transfer some of the pool’s `valueToken` to that protocol in exchange for interest-bearing tokens, or a DEX controller might swap one asset for another. The UFarmPool does not track individual investments; it relies on the PriceOracle to later report the total value of all assets (including whatever is deployed externally). The pool’s `_totalCost` is only updated upon receiving oracle info or when internal balances change from deposits/withdrawals. So after a protocol action, `_totalCost` might not immediately reflect new asset distribution – it will be updated on the next `quexCallback`.

**PoolWhitelist Integration and Arbitrary Controller:** UFarmPool inherits `PoolWhitelist` which provides:

* `isTokenAllowed(token)` overridden to allow the pool’s base token regardless of core whitelist (since core whitelist should include it anyway, this is mostly a convenience).
* `isProtocolAllowed(protocol)` via core’s whitelist.
* The flag `_useArbitraryController` initially false. If the fund is marked to allow arbitrary controllers, the fund manager can call `UFarmPool.setUseArbitraryController(true)` to override protocol allowance checks for this pool. That function requires the caller to have Fund Member and UpdateFundPermissions at the fund level and checks with core if the fund is allowed (`IUFarmCore.isAllowedArbitraryController(fund)` must be true). If so, it sets `_useArbitraryController = true`. When this flag is true, presumably `PoolWhitelist._checkProtocolAllowance` might allow any \_protocol (though in the given implementation, `_checkProtocolAllowance` doesn’t explicitly consider this flag). It’s possible that the `IController` for an “Arbitrary” protocol is whitelisted as a single generic entry, or that the pool’s controllers check `useArbitraryController()` at runtime to decide if they can proceed for unapproved protocols. The pool does provide `useArbitraryController() external view` to query the flag.

**ERC20 Features:** As an ERC20 token, the pool has `name`, `symbol`, and `decimals` defined. The `__init_UFarmPool_unchained` sets the token’s name and symbol (prefixed by “UFarm-” and “UF-”) when initializing. It also sets `valueToken` and verifies it’s whitelisted. It determines the share token’s decimals to match the value token’s decimals (`__decimals = ERC20(_valueToken).decimals()`), so that one share represents one unit of base asset when pool is empty or at inception. The `decimals()` override returns this stored `__decimals`.

The pool token’s total supply and balances change as deposits mint shares and withdrawals burn shares (or fees mint shares to fund/core). The contract inherits OpenZeppelin’s ERC20 logic for managing balances and allowances. Notably, the pool uses `_mintShares` internally which calls `_mint` (ERC20’s internal mint). Also, in `_processWithdrawal`, it calls `_burn(investor, shares)` to burn shares of an investor. Standard ERC20 events `Transfer` will be emitted for these, providing transparency of share distribution changes.

**External Interactions:**

* *With investors:* via `deposit` and `withdraw` functions. These are the only direct user-facing functions (apart from standard ERC20 transfer operations of pool tokens which investors could do peer-to-peer, although typically they wouldn’t trade pool shares externally due to likely restrictions).
* *With fund managers:* via `protocolAction` (to move assets into strategies) and indirectly via PoolAdmin (for config and status).
* *With Fund contract:* the fund might call `deposit` or use its special `withdrawFromPool(SignedWithdrawalRequest)` which essentially calls `withdraw` on the pool after verifying the signature and lockup at the fund level. The fund also queries `IUFarmPool.status()` and perhaps uses `getExchangeRate` or other view functions.
* *With PriceOracle:* the pool calls `quexRequest` on PriceOracle and receives `quexCallback` from the Quex oracle. The data flow through PriceOracle is crucial for correct operation; any failure in oracle responses could halt deposit/withdraw processing, which is why `sendQuexRequest` ensures only one outstanding request at a time for simplicity.
* *With external protocols:* via controllers as delegatecalls. The pool itself holds the actual assets (ERC20 tokens, possibly ERC721 if needed for some protocols like Uniswap v3 LP NFTs). It is marked `ERC721HolderUpgradeable`, meaning it can safely receive ERC721 tokens (perhaps if a protocol gives an NFT receipt, the pool can hold it). The controllers will handle calling external DeFi contracts. The pool uses SafeERC20 for all token transfers to external addresses (ensuring safe `ERC20.transfer` usage).

**Exchange Rate and Valuation:** The pool offers `getExchangeRate(uint256 __totalCost) view returns (uint256)`. This is a utility to compute the share token price given a hypothetical total cost. It essentially returns `(totalCost * 10^decimals) / (totalSupply + sharesToUFarm + sharesToFund)`. Notably, it calls `_calculateFee(__totalCost, config.managementCommission, config.packedPerformanceFee)` inside (without updating state) to determine `sharesToUFarm` and `sharesToFund` that *would* be minted if a fee accrual were done at this moment. It includes those in the denominator to get a slightly diluted total supply. This provides a forward-looking exchange rate including any un-accrued fees. This function is likely used off-chain for display or by the fund to quote an investor the current price per share.

**Summary of Pool function interactions:**

1. **Deposits:** Investor (or fund) calls deposit -> deposit queued -> oracle request -> oracle callback -> tokens transferred in, shares minted.
2. **Withdrawals:** Investor calls withdraw (possibly twice if lockup) -> withdraw queued (or triggers deactivation) -> oracle request -> oracle callback -> shares burned and tokens transferred out (if available; if not fully available, pool goes into deactivating and that withdrawal may be retried after assets are retrieved).
3. **Investments (Protocol Action):** Fund manager calls protocolAction -> Pool delegatecalls into controller -> controller moves pool’s assets (e.g. lend, swap, etc.) -> pool’s asset mix changes, which will reflect in next oracle valuation.
4. **Fees:** On every oracle callback (which happen whenever there’s deposits/withdrawals, or could be triggered periodically if implemented), fees are accrued by minting new shares to fund and core according to time and profit since last accrual. This means the fund and platform continuously earn fees without needing a separate transaction, integrated into the deposit/withdraw cycle or any oracle update cycle. (If the pool has long periods without deposits or withdrawals, there might be a mechanism to call `sendQuexRequest` periodically for fee accrual, or possibly the management fee is only realized during these events; this is a design choice.)

From a security perspective, UFarmPool is complex: it holds assets and uses delegatecalls for strategy execution. The critical security points are:

* Ensuring only authorized controllers (set by core) are used (enforced by whitelist).
* Ensuring the delegatecall context doesn’t allow malicious takeover: the `protocolInUse` and `_protocolTarget` can be used by controllers to guard sensitive operations. For example, a generic controller might only perform actions if `protocolInUse` matches an expected value and `_protocolTarget == address(this)` or some allowed address. Also, by default, controllers are trusted code; hence they should be audited as well, since they can manipulate the pool’s state extensively.
* The oracle process assumes a trustworthy oracle. The contract assumes `abi.decode(response.value, (uint256))` yields a valid total value. A compromised oracle could feed incorrect values, leading to mispriced shares (harming either investors or managers). There are likely off-chain checks or multiple data sources in the “Quex” network to mitigate this. For auditors, it’s important that the oracle’s data is verified or comes from a reliable process (the presence of flow registry and filters suggests a robust mechanism).
* The fee accrual minting to core and fund means the core contract ends up holding some pool shares. This could be considered when computing `isFund` or other checks. (Currently, core is not a fund, but core holds shares, which means core could withdraw those if needed by generating a withdrawal request signed by itself, etc. However, core has no provided method to do so; likely the platform owner could add one if they want to collect platform fees from the pool, or they could simply sell those shares via fund’s processes).
* The fund contract holding shares (from management fees) effectively means the fund manager’s fund has a stake in its own pool, aligning incentives and allowing the manager to share in profits beyond performance fees (if they keep those shares invested).

In conclusion, UFarmPool is the heart of funds’ operations, implementing a robust pattern for asynchronous deposits/withdrawals and on-chain accounting for fees. It leans on external controllers for strategy and an oracle for valuation, simplifying the pool’s internal logic to accounting tasks. Understanding UFarmPool is crucial for both developers and auditors since it deals with actual money movement and share issuance.

## PoolWhitelist (Token/Protocol Whitelisting)

**Purpose:** PoolWhitelist is an abstract contract included in UFarmPool (and PoolAdmin) that provides mechanisms to enforce that only approved tokens and protocols are used within pools. Rather than each pool having its own whitelist, PoolWhitelist checks against the **global whitelist** maintained in UFarmCore (via ICoreWhitelist). This ensures consistency: all pools across all funds adhere to the same allowed assets and DeFi protocols unless a specific fund/pool is granted an exception for arbitrary controllers.

**Token Allowance:** The function `isTokenAllowed(address token) public view virtual returns (bool)` in PoolWhitelist defers to the core’s whitelist: `return ICoreWhitelist(ufarmCore()).isTokenWhitelisted(token);`. UFarmPool overrides this to also allow its own `valueToken` unconditionally (which is typically already whitelisted by core). This double-check is harmless and ensures the base investment token is considered allowed for all operations (deposit, etc.). If a pool’s strategy involves acquiring a different token, that token must have been whitelisted in the core by the platform admin; otherwise, the pool’s controller should not be able to acquire it (and if it does, using it in `protocolAction` might be blocked by `_checkProtocolAllowance` if that token’s protocol isn’t allowed to be interacted with).

**Protocol Allowance:** Similarly, `isProtocolAllowed(bytes32 protocol)` uses core’s `isProtocolWhitelisted`. PoolWhitelist provides a modifier `protocolAllowed(bytes32 _protocol)` that calls `_checkProtocolAllowance(_protocol)`. The internal `_checkProtocolAllowance` simply reverts with `ProtocolNotAllowed` if `_isProtocolAllowed(_protocol)` returns false. By default, `_isProtocolAllowed` checks core whitelist.

**Arbitrary Controller Flag:** The variable `_useArbitraryController` is introduced in PoolWhitelist. If this is set to true, presumably the pool should be allowed to use a special controller that can interact with protocols not explicitly whitelisted.

For our documentation purposes, we explain the intent: if `_useArbitraryController` is set for a pool (which itself requires core approval per fund), the fund managers have more flexibility in deploying strategies that are not on the global whitelist. This feature might be used for experienced or internal funds that want to try new protocols without waiting for a platform update. Security-wise, it’s a flag that essentially waives the safety check of whitelisted protocols, so it should be granted sparingly. The core still has ultimate control since `isAllowedArbitraryController(fund)` at core must be true for the pool to enable it.

**Core Interaction:** PoolWhitelist requires knowledge of the core address to query whitelist. It defines an abstract `function ufarmCore() public view virtual returns (address);` which UFarmPool implements by returning its stored `_ufarmCore`. Thus, any call to `ICoreWhitelist(ufarmCore())....` in PoolWhitelist actually calls core.

**Summary:** PoolWhitelist itself doesn’t contain storage except `_useArbitraryController`. It acts as a bridge to the core’s whitelist, ensuring that any attempt to use a protocol or token in Pool logic first passes these checks. In practice:

* Deposits and withdrawals only deal with the `valueToken` (ensured to be whitelisted at init, else pool init would revert `TokenIsNotAllowed`).
* Protocol actions call `_checkProtocolAllowance` at the top of `protocolAction`, preventing calls for protocols that are not allowed.
* If arbitrary controllers are enabled, the assumption is the protocol check either always passes (if implemented accordingly) or the special generic protocol is used as a key.

For auditors, the whitelist ensures that even if someone tried to call a pool’s functions directly with manipulated data, the pool will not execute forbidden operations. For example, a malicious manager cannot make the pool interact with an unapproved contract unless the arbitrary flag is set by core. This limits the scope of what code can be executed via delegatecall (only known controller addresses) and what assets the pool can hold (only whitelisted ones, aside from possibly intermediate assets held briefly by controllers).

## PriceOracle (Oracle Integration Contract)

**Purpose:** PriceOracle serves as the on-chain component that communicates with an off-chain oracle network (referred to as *Quex*) to obtain pricing and valuation data needed by UFarm pools. It inherits from `PriceOracleCore` (containing core-linking logic and some base functions) and implements the `IQuexOracle` interface which defines methods for making oracle requests and handling flows. Essentially, PriceOracle allows UFarm to request data (like total pool value or asset prices) and forwards those requests to the Quex network, then receives the results which will be passed to the appropriate Pool via callback.

**Core Link and Initialization:** The PriceOracle contract is deployed separately (perhaps by the core’s deployment script) and then its initializer `__init__PriceOracle(address ufarmCoreLink, address _quexCore)` is called. In it, `__init__PriceOracleCore(ufarmCoreLink)` is invoked, likely storing the core address (the parameter name suggests `ufarmCoreLink` might actually be the core contract address or an instance of UFarmCoreLink interface). It also sets `quexCore = _quexCore` which is the address of the Quex Action Registry or main oracle contract on-chain, and emits `QuexCoreUpdated(_quexCore)` event. Once initialized and linked, UFarmCore calls `IUFarmCoreLink(priceOracle).coreCallback()` as part of its own initialization, which presumably marks the PriceOracle as linked to the core (for example, enabling `onlyLinked` modifiers if any, or simply confirming the relationship).

**Quex Oracle System:** The Quex system (not fully detailed here) involves:

* **QuexActionRegistry (quexCore):** a contract that coordinates oracle request. PriceOracle’s `quexCore` points to this.
* **FlowRegistry:** It handles creating “flows” – predefined queries or data streams. In the code, `IFlowRegistry` is used to create flows with `createFlow(Flow memory flow)`.
* **RequestOraclePool:** a contract to which actual HTTP requests (or data queries) are submitted. PriceOracle interacts with it to
* **PriceOracle (Oracle Bridge):** PriceOracle connects on-chain contracts to the off-chain price feed system (“Quex”). It holds the address of the Quex oracle core (`quexCore`) and provides methods for UFarm pools to create data *flows* and send data requests. It is initialized with the UFarmCore link and the Quex core’s address, and implements `IQuexOracle`. The core design is that a pool first **creates a “flow”** (a predefined query specification) via `PriceOracle.createFlow()`. In this call, PriceOracle takes the query template stored in its `quexActionData` (set by an admin) and inserts the pool’s address as an identifier (as an extra query parameter and as the callback target). It then registers this flow in the Quex FlowRegistry by calling `createFlow(flow)` and returns a `flowId`. The flow ties together: a gas limit for the callback, an action (data transformation defined by `patchId`, `schemaId`, `filterId`), the target oracle pool address for the HTTP request, the pool’s address as the *receiver* of the callback, and the function selector for `quexCallback`. Once a flow is created for a pool, the pool can later invoke `quexRequest(flowId)` to fetch data.

When a pool calls `quexRequest(uint256 flowId)` on PriceOracle, the PriceOracle forwards the request to the QuexActionRegistry: it calls `createRequest(flowId)` on the `quexCore` contract, sending along any ETH provided (to pay oracle fees). It then immediately refunds any unused ETH back to the caller (pool). The Quex system will process the request (for example, performing an HTTP API call off-chain) and eventually call back the designated pool’s `quexCallback(...)` function with the result. PriceOracle itself does **not** store price data or emit events per request – it serves as a pass-through for requests and a registry for flows.

**Oracle Flow Configuration:** The specifics of what data is fetched (e.g., price of an asset, or total portfolio value) are configured by an admin using `setQuexFlow(address requestOraclePool, HTTPRequest calldata request, bytes32 patchId, bytes32 schemaId, bytes32 filterId)`. This function, restricted to the UFarm core owner or an admin with “ManageQuexFeed” permission, updates the stored `quexActionData` – which includes an HTTP request template (method, host, path, body, headers, query parameters) and identifiers for how to parse and filter the response. Each call increments a `quexFlowVersion` counter. This allows the platform to update the oracle query (e.g., change the API endpoint or parsing logic) and signal pools if needed. Pools may choose to retrieve the latest `quexFlowVersion` to ensure they are using an up-to-date flow.

**Security and Permissions:** PriceOracle uses the core’s permission system to guard its admin function. The modifier `ownerOrHaveTwoPermissions(Permissions.UFarm.Member, Permissions.UFarm.ManageQuexFeed)` is applied to `setQuexFlow`, meaning only the core contract’s owner or a core admin with those two roles can reconfigure the oracle feed. Regular fund managers or pool contracts cannot alter the oracle queries – they can only invoke existing flows. This separation is important: it centralizes control over oracle endpoints to the platform governance, reducing risks of misconfiguration by individual funds.

**External Interaction:** PriceOracle interacts with:

* **UFarmCore:** at initialization for linking and for permission checks (it likely inherits `UFarmCoreLink`, and core calls a `coreCallback()` on it during setup).
* **UFarmPool:** pools call PriceOracle (for `createFlow` and `quexRequest`). Notably, `createFlow()` in PriceOracle adds an “id” parameter equal to the pool’s address (hex-encoded) to the HTTP request parameters and uses the pool’s address as the callback target in the Flow struct. This ensures the oracle network knows which pool to send data to. When `createFlow` is called, PriceOracle returns a `(flowId, flowVersion)` pair that the pool can store.
* **Quex Off-chain Network:** PriceOracle’s calls to `quexCore.createRequest` initiate off-chain work. The off-chain oracle network (via the QuexActionRegistry and related contracts) will eventually call `UFarmPool.quexCallback(requestId, data)` on the appropriate pool. PriceOracle itself is not called during the callback; the oracle network calls the pool contract directly (the callback address and selector were embedded in the flow).
* **QuexActionRegistry (Oracle Core on-chain):** PriceOracle’s `quexCore` variable is the address of this registry on-chain. It uses it for creating requests and retrieving fee information. For example, `getRequestFee(flowId)` in PriceOracle simply calls `IQuexActionRegistry(quexCore).getRequestFee(flowId)` to fetch the oracle’s fee requirements for a given flow. This allows the UI or pools to know how much ETH to supply when calling `quexRequest`.

**Workflow Recap:** A typical usage in context: After deploying a pool, the fund (or the pool itself, possibly in its constructor via the fund’s call) calls `PriceOracle.createFlow()` to register its interest in price updates. The PriceOracle prepares a Flow that tells the oracle network “for this pool address, fetch the data as per configured template and call back quexCallback”. The pool stores the returned `flowId`. Now, whenever the pool needs an updated valuation (e.g., when processing deposits or withdrawals), it calls `PriceOracle.quexRequest(flowId)` with some ETH for fees. PriceOracle passes the request to the oracle core and returns a requestId immediately. A short time later, the oracle network calls the pool’s `quexCallback` with that requestId and the resulting data (e.g., the latest total USD value of the pool’s assets). The pool verifies the callback came from the correct `quexCore` (PriceOracle provides a getter for `quexCore` which the pool uses to validate `msg.sender`). Once verified, the pool uses the data (decoding it to a uint256, as in our earlier discussion) to proceed with fee accrual and deposit/withdrawal processing.

By offloading heavy price computations or API calls to an off-chain service, UFarm keeps on-chain transactions lighter and only needs to handle the results. The PriceOracle acts as the secure intermediary making sure only authorized data flows are set up and that funds pay the required fees for oracle service. It is also upgradeable, so if the oracle interface or logic changes, the platform can deploy a new PriceOracle implementation via UUPS upgrade to adapt, without replacing the core or pool contracts.

## Controllers

### ArbitraryController & Guard

**Purpose and Role:** The ArbitraryController enables UFarm pools to execute arbitrary calls on external dApp contracts, but only for whitelisted protocols and methods. It acts as a generic adapter that forwards an encoded call (payload) to a target `dappAddress` on behalf of the pool. This is useful for integrating with external DeFi protocols in a flexible way without writing protocol-specific code for each case. The `Guard` contract works in tandem with ArbitraryController by maintaining a whitelist of allowed contract addresses and function signatures. Together, they ensure only approved external interactions occur via the ArbitraryController.

**Internal Implementation:** The ArbitraryController’s main function `performAction` takes a bytes32 identifier (`dapp`), a target address, call data (`payload`), and an ETH value. It first validates that the call data is not empty and then consults the Guard: calling `guard.isProtocolAllowed(dapp, dappAddress, payload)` to check if the combination of protocol id, address, and function selector is permitted. The `Guard` contract implements this by extracting the 4-byte function selector from the payload (via assembly) and looking up a boolean in its `allowedMethods` mapping. This mapping is managed through admin functions `addAllowedMethods`/`removeAllowedMethods` (restricted to the contract owner or authorized roles) which mark specific method signatures as allowed for a given dApp id and address. If the Guard whitelist check fails, `performAction` reverts with `ProtocolOrPayloadNotAllowed`. Assuming the call is allowed, the ArbitraryController next ensures that the pool itself is authorized to use the arbitrary call feature – it calls `IUFarmPool(address(this)).useArbitraryController()` and expects `true`, else it reverts (each pool can toggle whether arbitrary calls are enabled for it). Finally, the controller executes the external call: `dappAddress.call{value: value}(payload)`. The call is made as a low-level `.call` (forwarding ETH if `value > 0`), and if it returns a failure (`success == false`), the controller reverts with `ExternalCallFailed`. On success, an `Executed` event is emitted with the dApp identifier and payload. Notably, ArbitraryController inherits OpenZeppelin’s ReentrancyGuard and a custom `NZGuard` (non-zero guard) to prevent reentrant calls and ensure non-zero inputs respectively.

**Invocation via UFarmPool:** The ArbitraryController is not meant to be called directly; instead, it is designed to be invoked via a delegatecall from a UFarmPool contract. The code and documentation enforce this: the contract’s notice explicitly states that `performAction` “must be called via delegatecall from a UFarmPool contract”. In practice, the UFarmPool likely has a mechanism to delegatecall into controller contracts (using the pool’s storage/context). A modifier `checkDelegateCall` (defined in the base `Controller` class) is applied to `performAction` to enforce this requirement. This means if someone tried to call `performAction` directly on the controller contract, the call would be rejected. When invoked by delegatecall, `address(this)` in the controller code actually refers to the pool’s address, which is crucial for the Guard check and for any state changes (though ArbitraryController itself keeps no mutable state except perhaps ReentrancyGuard status). Moreover, by using delegatecall, any tokens moved or external actions happen in the context of the pool (the pool holds the tokens and receives any outputs). The Guard contract’s check doesn’t explicitly verify delegatecall, but the ArbitraryController’s logic indirectly does – for example, it calls `IUFarmPool(address(this))...` which will only succeed if `address(this)` is a UFarmPool implementing that interface. In summary, UFarmPool acts as the executor, and ArbitraryController is a library-like component providing the logic, ensuring the call originates from a trusted pool.

**Security Mechanisms:** Several layers of security protect ArbitraryController’s usage. First, the whitelist in Guard is a primary defense: only explicitly allowed protocol addresses and function selectors can be called, preventing arbitrary or malicious calls. The list is managed by authorized addresses (owner or those with `ManageWhitelist` permission) to ensure governance over what external interactions are permitted. Second, the `checkDelegateCall` modifier ensures an ArbitraryController call cannot be executed in isolation – it requires the context of a UFarmPool, which presumably means only the pool’s logic (governed by UFarm’s core contracts) can trigger it. Third, the function is marked `nonReentrant` (from ReentrancyGuard) to prevent reentrancy attacks. This is important because `performAction` makes an external call (`dappAddress.call`), and reentrancy guard prevents an attacker from re-entering the pool (via another malicious call back into the pool’s delegatecall function) before the first call finishes. Additionally, the `NZGuard` parent imposes `nonZeroAddress` and `nonZeroBytes32` checks (we see it used in the constructor and function modifiers) to avoid using null addresses or identifiers. Finally, by forcing any ETH (`msg.value`) to be explicitly passed through the `value` parameter and doing the call in a controlled manner, the contract avoids confusion around value transfers. In summary, ArbitraryController & Guard together ensure that only pre-vetted external protocol calls can be made by a pool, that the call is executed in the correct context, and that common attack vectors (like reentrancy) are mitigated.

### OneInchV5Controller

**Purpose and Role:** The OneInchV5Controller is a specialized controller that enables UFarm pools to perform token swaps using the 1inch Aggregation Router (v5). Its role in the UFarm architecture is to provide an integration with the 1inch aggregator, allowing a pool to swap assets across various liquidity sources through 1inch’s API in a single transaction. Instead of the pool implementing the complex swap logic, it delegates to this controller which knows how to interact with 1inch’s contracts. According to the contract description, it is specifically a “Controller contract for 1Inch V5 aggregation router”. This means the controller is essentially a wrapper that prepares calls to the 1inch router contract (`aggregationRouterV5`) and handles the result, all within the pool’s context.

**Internal Logic and Implementation:** The OneInchV5Controller provides two main external functions: `delegated1InchSwap(bytes _data)` for executing a single swap transaction via 1inch, and `delegated1InchMultiSwap(bytes[] _multiData)` for chaining multiple swap calls sequentially. Both functions are intended to be called by the pool via delegatecall and thus have the `checkDelegateCall` and `nonReentrant` modifiers.

The core swap execution is handled by the internal function `_run1InchSwap(bytes _data)`, which interprets the calldata and directs it to the appropriate 1inch function. The controller first reads the first 4 bytes of `_data` to determine which function of the 1inch router is being requested (for example, `swap`, `unoswap`, `unoswapTo`, `uniswapV3Swap`, etc.). Depending on the method selector, it decodes the parameters accordingly and performs necessary pre-checks:

* **`unoswapTo` selector:** This corresponds to 1inch’s function for Uniswap V2-style swaps where output is sent to a specified recipient. The controller decodes `(recipient, tokenIn, amountIn, minReturn, pools)` from the data. It then **verifies the recipient is the pool itself** (address(this)), as the pool should receive the output tokens and not an arbitrary address. If the recipient isn’t the pool, it reverts with `InvalidRecipient()`. Next, it records `tokenIn` and checks that this token is allowed in the pool via `_onlyIfTokenAllowed`. The `_onlyIfTokenAllowed` helper queries the PoolWhitelist to ensure the token is approved for use in the pool (or is the special case native token address). It then iterates through the array of pool addresses (`pools`) representing the swap path; for each Uniswap V2 pair address in the path, it finds the pair’s two tokens and determines the next intermediate token in the path. At each hop, it calls `_onlyIfTokenAllowed` on the intermediate output token as well, effectively ensuring every token that will be acquired along the path is whitelisted. After the loop, the final `tokenOut` is determined (the last token in the path).
* **`unoswap` selector:** Similar to above, but for 1inch’s function where output goes to caller (here, the pool by default). It decodes `(tokenIn, amountIn, minReturn, pools)` and follows the same process: initial tokenIn allowed check, then iterate through `pools` to derive the final output token and ensure all intermediate tokens are allowed. The difference is that because output goes to the caller by default, there’s no explicit recipient param to check (implicitly, the pool will receive as it’s the execution context).
* **`uniswapV3SwapTo` selector:** This corresponds to a 1inch call that performs a Uniswap V3 multi-hop swap with a specified recipient. The controller decodes `(recipient, amountIn, minReturn, pools)`. It requires `recipient == address(this)` (pool) or reverts. The `pools` array in 1inch’s format encodes both the pool address and the direction for each hop (using the highest bit of the 256-bit value to indicate token order). The controller loops through each pool in the path, using `IUniswapV3Pool.token0()` and `.token1()` to get the token addresses. For the first pool, it determines `tokenIn` and `tokenOut` based on the `zeroForOne` flag (which indicates which token is being swapped for which). It checks that the initial `tokenIn` is allowed. For each hop (including the first and subsequent pools), it checks that the output token of that hop is allowed. By the end, it identifies the final `tokenOut`.
* **`uniswapV3Swap` selector:** Similar to `uniswapV3SwapTo` but without an explicit recipient (output goes to caller/pool). It decodes `(amountIn, minReturn, pools)`, then iterates through the pools to figure out the path’s tokens, checking allowed tokens similarly.
* **`swap` selector:** This corresponds to the primary 1inch Aggregation Router function that can handle arbitrary paths and DEXs via a `SwapDescription`. The controller decodes the call as `(address executor, SwapDescription swapDesc)` – it ignores the executor address (allowing only the provided one) and reads the swap description. From `swapDesc`, it extracts `tokenIn = srcToken`, `tokenOut = dstToken`, `amountIn`, and `minReturnAmount`. It **verifies that the designated `dstReceiver` in the swapDesc is the pool** (`address(this)`), disallowing swaps that send proceeds elsewhere. It then checks that `tokenOut` is allowed in the pool. (It does not explicitly check `tokenIn` here, presumably because `tokenIn` would be a token the pool already holds, but all new tokens entering the pool are gated by allowed `tokenOut`).
* **Unknown selector:** If the function selector in `_data` doesn’t match one of the expected ones above, the controller reverts with `InvalidMethod()`.

After parsing and validation, the `_run1InchSwap` function prepares to execute the swap via the actual 1inch router contract. If `amountIn` or expected `amountOut` is zero (meaning something went wrong in decoding or an empty swap), it reverts `OneInchSwapFailed()`. Otherwise, it uses `SafeOPS._forceApprove(tokenIn, aggregationRouterV5, amountIn)` to ensure the 1inch router contract is approved to pull the `amountIn` of `tokenIn`. This is done in a safe manner (likely setting the allowance exactly to `amountIn`, and using a helper that guards against known ERC20 issues). Then it calls the 1inch router using `SafeOPS._safeCall(aggregationRouterV5, _data)`, which performs the external call to the aggregator contract. The result of the call (which is 1inch’s return data) is captured. For 1inch’s `swap` function, the return data contains two 256-bit values: amountOut and amountSpent. The controller expects the first word to be the actual output amount received. It uses assembly to read the returned `amountOutResult`. If the actual output is less than the minimum expected (`amountOut` which was `minReturnAmount` from SwapDescription, or analogous in other methods), it reverts `OneInchSwapFailed()`. Otherwise, it updates `amountOut` to the actual received amount. (For the specialized methods like `unoswap`, the 1inch router likely reverts internally if minimum output isn’t met, but this check adds an extra safety net.)

Finally, when the swap (or sequence of swaps) is completed, the controller calls an internal hook `_afterSwapExecuted(tokenIn, tokenOut, amountIn, amountOut)`. In OneInchV5Controller, this simply emits the event `SwapOneInchV5(tokenIn, tokenOut, amountIn, amountOut, PROTOCOL())`. The `PROTOCOL()` function for this controller returns a constant hash identifying it as "OneInchV5". In the multi-swap scenario (`delegated1InchMultiSwap`), the controller calls `_run1InchSwap` for the first element in the `_multiData` array, then in a loop calls `_run1InchSwap` for each subsequent element. It chains the swaps by simply discarding intermediate `tokenIn`/`amountIn` (after the first swap) and using the output of each call as the input to the next. In practice, each `_run1InchSwap` already handles transferring and swapping using the pool’s tokens; performing them sequentially in one transaction means the output from swap 1 is now held by the pool and becomes the input for swap 2, and so on. After the final swap, `_afterSwapExecuted` is invoked once with the initial `tokenIn` and total `amountIn` from the first swap, and the final `tokenOut` and final `amountOut` from the last swap.

**How It’s Called (Delegatecall from Pool):** Similar to the ArbitraryController, the OneInchV5Controller’s functions are meant to be used via delegatecall by a UFarmPool. All external functions (`delegated1InchSwap`, `delegated1InchMultiSwap`) have the `external` visibility and the `checkDelegateCall` modifier, indicating they will only execute correctly in the context of a pool contract. When the pool wants to execute a 1inch swap, it likely prepares the call data (perhaps using 1inch API off-chain to get the encoded transaction `_data` or `_multiData` sequence) and then invokes the controller’s function via delegatecall. Within the delegatecall, `address(this)` refers to the pool, so all token transfers, approvals, and recipient addresses are the pool’s. The controller itself holds an immutable reference to the 1inch router’s address (`aggregationRouterV5` is set in its constructor), so the pool doesn’t have to supply the router address each time – it’s baked into the controller logic. This design means the pool delegates the heavy lifting to the controller but remains the executor of the swap: the pool’s balances are debited/credited as tokens are swapped, and any ETH sent for gas or swap is from the pool (the controller functions are payable if needed, though in the code we see `msg.value` usage is handled by simply forwarding the value in the call). By using delegatecall, the pool can integrate with 1inch without giving custody of its tokens to an external contract; instead, the controller (as library code) uses the pool’s own allowance and balance to swap directly with the external 1inch router. The events emitted (SwapOneInchV5) are also logged in the context of the pool’s address (since `this` is pool), which is useful for tracking pool activity.

**Security Measures:** The OneInchV5Controller has several built-in security and safety features. Like all UFarm controllers, it employs `checkDelegateCall` to prevent direct usage and `nonReentrant` to guard against reentrancy attacks on its functions. This means only a UFarmPool (which presumably itself is secure and only callable through governed mechanisms) can initiate swaps, and an in-flight swap cannot be re-entered. Additionally, the controller ensures that **all tokens that enter the pool as a result of the swap are approved tokens**. It uses the PoolWhitelist interface (`IPoolWhitelist`) to check `isTokenAllowed` for the final output token and every intermediate token in multi-hop paths. If any token is not whitelisted, it will revert (`TokenIsNotAllowed` error). This prevents a scenario where an unexpected or malicious token could be swapped into the pool. It even hardcodes allowance for the Ethereum pseudo-address (`0xEeeee...EEeE` which 1inch uses to denote native ETH) as allowed. Another important check is forcing the **recipient of all swaps to be the pool itself**. The controller will reject any attempt to route the output to an external address by checking `recipient == address(this)` on relevant 1inch calls (both for Uniswap V2 and V3 style methods, as well as the SwapDescription’s `dstReceiver`). This ensures the pool retains custody of the swapped assets and an attacker cannot redirect proceeds.

Furthermore, when calling the 1inch router, the controller uses the SafeOPS library to safely approve the tokens and execute the call. `SafeOPS._forceApprove` likely handles setting the exact allowance needed for the router (and possibly resetting it to zero after, though in the provided code we see it setting but not clearing – which might be fine as long as it’s exactly the amount used). This mitigates ERC20 vulnerabilities like the old approve race-condition and ensures the router can pull the tokens without issue. The `SafeOPS._safeCall` wrapper probably catches any revert and returns it as a false `success` with `result` which the controller then interprets; this adds an extra layer of safety so that if 1inch’s call fails (due to slippage or any error), the controller can handle it gracefully. The explicit post-call check on output (`amountOutResult < amountOut` leading to revert) double-checks that the router honored the minimum output requirement. If not, it treats it as a failure. All these checks happen atomically within one transaction (since it’s a single function call via delegatecall), meaning either the entire swap sequence succeeds and the pool ends up with the new token, or it fails and reverts to the previous state (no partial completion). Finally, the controller emits the `SwapOneInchV5` event with details, which not only is useful for logging but also includes the `protocol` field (a bytes32 hash) identifying the controller – this can serve as an audit trail to ensure the action was done via the correct controller. In summary, the OneInchV5Controller’s design tightly restricts how 1inch is used: only the predefined router can be called, only whitelisted tokens can come out, outputs must go to the pool, and known attack vectors (like reentrancy and unauthorized direct calls) are addressed.

### UnoswapV2Controller

**Purpose and Role:** The UnoswapV2Controller is responsible for handling token swaps and liquidity provisioning operations on Uniswap V2-like AMMs (Automated Market Makers) for the UFarm system. In essence, it lets a UFarm pool swap its assets via a Uniswap V2 (or SushiSwap, PancakeSwap, etc., any AMM following Uniswap V2 pattern) and add or remove liquidity (LP tokens) on such AMMs. The name “UnoswapV2” suggests it’s a unified interface for Uniswap V2 style exchanges. The contract is marked `abstract`, indicating it may be extended for concrete deployments (perhaps to supply the specific init code hash for different networks). Its constructor takes addresses for a UniswapV2 factory, router, and a price oracle, plus the factory’s init code hash, which means this controller is somewhat configurable to different Uniswap V2 deployments. Within UFarm’s architecture, this controller allows a pool to trade between assets it holds, or to provide liquidity to earn yield, all through delegatecalls (so the pool itself executes the Uniswap operations). This modularizes AMM interactions outside of the core pool logic.

**Swap Logic (Swapping Tokens):** The primary swap function is `delegateSwapExactTokensForTokens(bytes _data)`, which is analogous to Uniswap V2’s `swapExactTokensForTokens` but implemented internally. This function, decorated with `checkDelegateCall` and `nonReentrant`, is intended to be called via delegatecall by the pool. It expects `_data` to encode a struct `UniV2SwapExactTokensForTokensArgs` (which contains `amountIn`, `amountOutMin`, `deadline`) and an array `path` of token addresses. The controller decodes these inputs and first checks that the current block time is not past the provided deadline (by `_checkDeadline(deadline)`), which will revert if the operation is too late. This prevents stuck transactions or replay far in the future.

It then ensures the swap path has at least two addresses (source and destination) – if not, it reverts `INVALID_PATH()`. The path is an array like \[tokenIn, tokenMid..., tokenOut]. The function retrieves the pool’s whitelist interface to enforce allowed tokens: it checks that the second token in the path (`path[1]`, which is the first output token of the first swap hop) is allowed in the pool. (The reasoning is that if tokenOut of the first hop were not allowed, the pool shouldn’t acquire it. The initial tokenIn is presumably already in the pool, and the final tokenOut will be checked at the end against `amountOutMin`, but intermediate outputs must also be allowed to avoid introducing forbidden tokens mid-swap). Next, it prepares for the first swap. In Uniswap V2, to swap from tokenA to tokenB, you transfer tokenA into the pair contract and then call `pair.swap()` specifying the amount of tokenB you want out. The controller identifies the correct pair for the first two tokens in the path. It computes `reversed = tokenIn > tokenOut` (a simple comparison of addresses). This is used to sort the pair tokens in the correct order since Uniswap pairs are identified by sorted token addresses. It then assigns `tokenA = (reversed ? tokenOut : tokenIn)` and `tokenB = (reversed ? tokenIn : tokenOut)`. Now `tokenA` and `tokenB` are the two tokens in sorted order. It computes the pair address by calling `pairFor(tokenA, tokenB)`. Internally, `pairFor` likely uses the stored `factory` and `FACTORY_INIT_CODE_HASH` to derive the pair address by hashing the two token addresses (or it might call `factory.getPair(tokenA, tokenB)`). The result is cast to `IUniswapV2Pair pair`.

The controller then transfers the input tokens from the pool to the pair: `IERC20(tokenIn).safeTransfer(address(pair), amountIn)`. It uses OpenZeppelin SafeERC20 for safety. At this point, the pair has `amountIn` of tokenIn transferred in. It calculates where the output of this swap should be sent: if the path has more than 2 tokens (meaning at least one intermediate hop), the output of this first swap should be sent directly to the next pair contract, not to the pool yet. So it sets `swapTarget = (pathLength > 2) ? pairFor(tokenOut, path[2]) : address(this)`. If there is another hop, `swapTarget` is the address of the pair for tokenOut and the next token in path (path\[2]); if this is the final hop, `swapTarget` is just the pool (address(this)), meaning the output will come to the pool.

Next, it queries the pair’s reserves: `(reserve0, reserve1,) = pair.getReserves()`. Uniswap pairs keep reserves of token0 and token1. Because the controller knows the sort order (which token was tokenA and tokenB), it knows which reserve corresponds to tokenIn vs tokenOut. It then calculates the amount of `tokenOut` that this `amountIn` should yield, given the reserves and Uniswap’s formula. There is a helper `getAmountOutReserves(amountIn, reserveIn, reserveOut)` used, which likely implements: `amountOut = amountIn * 997 / 1000 * reserveOut / (reserveIn * 1000 + amountIn * 997)` (the constant product formula with 0.3% fee). The code passes `reversed ? reserve1 : reserve0` as the `reserveIn` and the opposite as `reserveOut` depending on which way around the swap is. This yields `amountOut` for the first swap. It then calls `_checkOutAmount(amountOut, 1)`. This appears to ensure `amountOut` is at least 1 (non-zero). Essentially, if due to rounding or tiny input the output would be 0, it will revert `INSUFFICIENT_OUTPUT_AMOUNT()` (likely defined as error). This check with a minimum of `1` is used for intermediate hops to ensure progress; the final hop will be checked against the user-specified `amountOutMin` later.

Now the swap is executed: `pair.swap(reversed ? amountOut : 0, reversed ? 0 : amountOut, swapTarget, new bytes(0))`. This call invokes the Uniswap pair’s swap function, specifying how much of each token to send out. If `reversed` is true (meaning tokenIn was the larger-address token, so tokenOut corresponds to token0 of the pair), then it sets `amount0Out = amountOut` and `amount1Out = 0` (meaning output token0, which is tokenOut in that case). If `reversed` is false (tokenIn is token0, tokenOut is token1), it sets `amount0Out = 0, amount1Out = amountOut`. The `swapTarget` we calculated is provided as the recipient of the output tokens. Importantly, this allows chaining: for multi-hop, the first swap’s output is delivered straight into the next pair contract. For a single-hop swap, `swapTarget` is the pool itself, so the output goes to the pool. The `bytes(0)` is just an empty data field because we’re not using Uniswap’s flash swap feature.

After this swap, if the path had more than 2 tokens (meaning there are more hops to execute), the function enters a loop to handle the subsequent swaps. The loop runs from `i = 0` to `i < pathLength - 2`. Each iteration handles swap from `path[i+1]` to `path[i+2]`:

* It sets `tokenIn = path[i+1]` and `tokenOut = path[i+2]`. For the first iteration after the initial swap, this would set tokenIn to what was tokenOut of the previous swap.
* It checks that `tokenOut` is allowed in the pool (again, to avoid introducing disallowed assets).
* It computes `reversed` for this pair (compare addresses) and sorts tokenA/tokenB accordingly.
* Now, note that at the end of the previous swap, we set `swapTarget` to the next pair’s address. So the variable `pair` is updated: `pair = IUniswapV2Pair(swapTarget)`. This means `pair` now points to the Uniswap pair contract for the current `tokenIn` and `tokenOut`.
* It then sets up the next `swapTarget`: if there is yet another hop after this (i < pathLength - 3), set `swapTarget = pairFor(tokenOut, path[i+3])` (the following pair’s address), otherwise if this is the last hop, `swapTarget = address(this)` (the pool).
* It retrieves reserves from the current `pair`.
* It uses `getAmountOutReserves` to compute the new `amountOut` given the previous `amountOut` as input (notice in the code, they reuse the variable `amountOut` — at the end of the first swap, `amountOut` held the output of the first swap; now in the loop, they treat that as the input for the second swap calculation). Essentially, it’s chaining the formula: the output of one swap becomes the input for the next.
* `_checkOutAmount(amountOut, 1)` is called for this intermediate output as well, ensuring it’s non-zero.
* It then calls `pair.swap(...)` on this pair, similarly outputting `amountOut` of tokenOut to the `swapTarget` (either the next pair or the pool if it’s the final hop). This executes the intermediate swap.

The loop continues for each intermediate hop in the path. By the end of the loop, the last swap’s output has either been sent to the next pair or, if it was the final hop, to the pool. After exiting the loop (meaning all hops done), the code performs a final check: `_checkOutAmount(finalAmountOut, swArgs.amountOutMin)`. Here `amountOut` represents the output of the last swap (the final token acquired). It verifies that this final amount is at least the user-specified minimum (`amountOutMin` from the decoded args). If not, it will revert with `INSUFFICIENT_OUTPUT_AMOUNT()` (as Uniswap would do). If the check passes, the swap is complete. It then emits the `SwapUnoV2` event, logging the swap details. The event includes `tokenIn` (which the code sets back to the initial path\[0] at line 317), the final `tokenOut`, the initial `amountIn`, the final `amountOut`, and the protocol identifier. The `PROTOCOL()` for this controller likely returns a unique bytes32 (perhaps something like keccak("UnoswapV2") if implemented).

Important to note: this internal implementation doesn’t actually call the Uniswap V2 Router’s functions; it effectively reimplements the swap logic (which is feasible because Uniswap V2’s core contracts allow direct interaction with pairs). This saves gas and grants more control (like directing outputs to intermediate pairs directly, which the Router also does under the hood). It also uses the pool’s balances directly via delegatecall.

**Liquidity Addition (Add Liquidity):** Another key capability is adding liquidity to a Uniswap V2 pair. This is handled by `delegatedAddLiquidity(bytes _data)`. This function is also `external checkDelegateCall nonReentrant`. It expects `_data` encoding a `UniV2AddLiquidityArgs` struct, containing `tokenA`, `tokenB`, `amountADesired`, `amountBDesired`, `amountAMin`, `amountBMin`, and `deadline`. These correspond to the usual parameters for adding liquidity (desired amounts of two tokens, with minimum bounds and a deadline). The controller decodes these and checks the deadline similarly. It then ensures both token addresses are allowed in the pool (the pool should not supply liquidity with tokens it isn’t supposed to hold).

The controller uses an interesting approach to determine how much of each token to actually contribute. In Uniswap V2, when adding liquidity, you usually provide tokens in the ratio of the pool’s current reserves; if you specify more of one token than needed, some of it is returned. Here, the controller calls `thisController.quoteExactLiquidityAmounts(tokenA, tokenB, amountADesired, amountBDesired, amountAMin, amountBMin, deadline)`. Note that it first does `UnoswapV2Controller thisController = _delegatedThisController();`. This likely obtains a reference to call the controller’s own view function via an external call (since we are in a delegatecall context, calling a view might require using the actual contract’s code). The `quoteExactLiquidityAmounts` presumably returns the exact amounts of A and B that should be provided (clamped by the `min`/`desired` constraints and matching the pool ratio) and the address of the pair to which liquidity will be added. Essentially, it might be computing how much of each token will actually be spent such that the proportion matches the pool’s current price and both are within the provided bounds. The result is `(amountA, amountB, pairAddress)`.

With the optimal amounts known, the controller then transfers those token amounts from the pool to the pair contract: it transfers `reversed ? amountB : amountA` of `tokenA` and `reversed ? amountA : amountB` of `tokenB` to the pair. Here again it sorts token order by comparing addresses (tokenA > tokenB means reversed) to align with how the pair contract expects deposits. Essentially, it ensures token0 gets amountA and token1 gets amountB. After transferring the tokens, it calls `pair.mint(address(this))` on the pair contract. In Uniswap V2, the `mint(to)` function on the pair takes the tokens that have been sent to it and mints LP tokens to the given address. They pass `address(this)` (which in delegatecall context is the pool) as the recipient, so the pool receives the liquidity tokens (LP tokens). The pair contract will calculate how many liquidity tokens to mint based on the added reserves. The controller then checks the returned `liquidity` amount; if it is 0, it means the liquidity addition failed (e.g., one of the token amounts was insufficient or the pair had no liquidity yet and something was off), so it reverts `INSUFFICIENT_LIQUIDITY()`. If liquidity > 0, the operation succeeded. The controller emits `LiquidityAddedUnoV2(tokenA, tokenB, amountA, amountB, liquidity, pair, PROTOCOL())` to record the event. This event includes the actual amounts of each token used, the amount of LP tokens minted, and the pair address.

**Liquidity Removal (Remove Liquidity):** To remove liquidity from a Uniswap V2 pair, the controller provides `delegatedRemoveLiquidity(bytes _data)`, which takes a `UniV2RemoveLiquidityArgs` struct with `tokenA, tokenB, liquidity, amountAMin, amountBMin, deadline`. After decoding and deadline check, it ensures the token ordering is sorted (if tokenA > tokenB, it swaps them and also swaps the amount min constraints accordingly). This ensures it will target the correct pair. It then determines the pair address via `pairForSorted(tokenA, tokenB)` (explicitly for sorted tokens). The pool presumably holds some LP tokens for that pair (perhaps from previous add liquidity). The controller transfers the specified `liquidity` amount of the LP token from the pool to the pair contract: `IERC20(pair).safeTransfer(pair, liquidity)`. This prepares the pair to burn those LP tokens.

Next, it calls `pair.burn(_target)`. In Uniswap V2, `burn(to)` will burn the LP tokens and send out the underlying token A and B amounts to the specified address. Here, the controller determines a `_target` address for the withdrawal. The code snippet shows it obtaining `(_target, _withdrawalHash) = _getTarget()`. This implies there is logic to figure out where the withdrawn tokens should go. Likely, if a user initiated this removal as part of a withdrawal from the pool, `_target` might be the user’s address. If it’s an internal operation (like the pool rebalancing), `_target` could be the pool itself. The `_withdrawalHash` might be used for tracking or events. The pair’s `burn` function returns `(amountA, amountB)` – the amounts of each token released. The controller then checks that `amountA` is at least `amountAMin` and `amountB` is at least `amountBMin` (these minima come from the struct, likely to ensure the pool doesn’t get less than expected due to slippage). If either is too low, it reverts with `INSUFFICIENT_A_AMOUNT` or `INSUFFICIENT_B_AMOUNT`.

After a successful burn, if `_target` is not the pool itself, that means the liquidity removal was done on behalf of some external recipient (for example, a user withdrawing assets from the pool). In that case, the controller emits `IUFarmPool.Withdraw(_target, tokenA, amountA, _withdrawalHash)` and similarly for tokenB. These are events defined in the UFarmPool interface presumably to log that tokens A and B were withdrawn to the user. Then it emits `LiquidityRemovedUnoV2(tokenA, tokenB, amountA, amountB, liquidity, pair, _target, PROTOCOL())`. This event captures the details of the liquidity removal including who ultimately received the tokens (target).

Thus, the remove liquidity flow will either send the underlying tokens back to the pool (if `_target` is pool) or directly out to a user (if `_target` is a user’s address), which is a flexible design to accommodate different use cases (e.g., an end-user redeeming their share of the pool’s liquidity).

**Delegatecall Usage:** All functions in UnoswapV2Controller are meant to be called via delegatecall from the pool. We see `delegateSwapExactTokensForTokens`, `delegatedAddLiquidity`, and `delegatedRemoveLiquidity` all use `external` with `checkDelegateCall`, enforcing that context. This means the pool’s address and storage are in play when these run. For instance, the LP tokens or assets are held by the pool, and the transfers are moving them from the pool’s balance. The events emitted will be under the pool’s address. The pool effectively “borrows” the controller’s logic. Also, because it’s delegatecall, any state variables in the controller (like the stored factory address, router, etc., which are `immutable` in the controller code) actually reside in the controller’s own contract, not in the pool. However, since they are immutable and used only in the controller’s code, the code can fetch them (the code knows its own immutables). Immutables in delegatecall context are tricky: in delegatecall, `address(this)` is the pool, so how does the code read an `immutable` which is normally stored in code’s address space? In Solidity, `immutable` variables are compiled as constants stored in code or at fixed positions; they might not be accessible via delegatecall. It’s possible that in deployment, each pool might have its own instance or there’s a pattern where the controller is not truly a library but an upgradeable logic that is set in pool storage. However, given the naming, possibly each network’s UFarm might deploy a concrete subclass of UnoswapV2Controller with the proper addresses (factory, router) and then use that contract’s code. The delegatecall would then execute that code. If it’s a library call, those addresses might be inlined. Assuming that’s handled, from the pool’s perspective, using these controllers via delegatecall means it can perform complex AMM operations without permanently handing control to external contracts.

**Security and Checks:** UnoswapV2Controller has multiple safeguards:

* **Reentrancy Guard:** All external functions use `nonReentrant` to avoid reentrant calls. Given it directly interacts with Uniswap pairs (which call ERC20 transfers), reentrancy could be a concern if a token’s transfer triggers a callback. The guard ensures the pool can’t be re-entered during an ongoing swap or liquidity operation.
* **Delegatecall-only:** The `checkDelegateCall` modifier ensures only the pool can call these functions, preventing misuse by outsiders or sending the pool’s tokens to unintended targets.
* **Allowed Tokens Only:** Before performing swaps or adding liquidity, the controller checks with `IPoolWhitelist` that any token the pool is about to receive or deal with is allowed. In swaps, it checks each intermediate and final token; in adding liquidity, it checks both tokens being added (since adding an unallowed token would violate pool rules). Removing liquidity doesn’t explicitly check allowed tokens because those tokens were presumably allowed when added (and if the pool held LP, it implies both tokens were allowed).
* **Slippage/Deadline Controls:** The presence of `amountOutMin` in swaps and `amountAMin/BMin` in liquidity ops, along with `deadline`, provides typical slippage and timing protection. The controller enforces these: if the actual output of a swap is less than `amountOutMin`, it reverts; if the amounts from removing liquidity are less than minimums, it reverts. Deadlines prevent the transaction from being executed much later when conditions might have changed.
* **No direct price oracle usage (except possibly for quoting):** The controller has a `priceOracle` address stored and a function `quoteOptimalLiquidityAmount` and others, implying it can fetch or calculate optimal liquidity distribution. However, the actual add liquidity uses `quoteExactLiquidityAmounts` which might internally use the oracle for something, but in the snippet we saw, it likely just uses current reserves. The existence of priceOracle suggests the controller might consult it to ensure fair pricing or avoid large price impacts (possibly not shown in the parts we excerpted).
* **Mathematical Safety:** By using `SafeERC20.safeTransfer`, it ensures token transfers are successful (non-zero return or not false). The custom math functions (like `UFarmMathLib` possibly for precise calculations) and explicit formulas help avoid relying on the external router. Also, by computing outputs via reserves and formula, it trusts the on-chain data and doesn’t call `router.getAmountsOut` except in the provided `getAmountOut` view function (which is a safe view call anyway).
* **Events for transparency:** Swap events (`SwapUnoV2`) and liquidity events (`LiquidityAddedUnoV2`, `LiquidityRemovedUnoV2`) are emitted. These ensure that any movement of assets via the controller is logged, which is important for auditing pool activity and debugging.

In summary, UnoswapV2Controller is a comprehensive module handling Uniswap V2 interactions. It carefully manages token transfers directly with pair contracts, ensures the pool only trades in allowed assets, and upholds Uniswap’s invariants and UFarm’s safety constraints. By keeping the actual logic in this controller, UFarm can upgrade or modify how AMM interactions work without changing the pool contract, and possibly reuse the logic for multiple pools.

### UnoswapV3Controller

**Purpose and Role:** The UnoswapV3Controller enables UFarm pools to interact with Uniswap V3 or similar concentrated liquidity AMMs. Uniswap V3 introduces more complex liquidity management (positions represented as NFTs, with specific price ranges) and different swap functions. This controller abstracts those details so that a UFarm pool can swap tokens on Uniswap V3 and manage liquidity positions (mint, increase, decrease, collect fees, burn) through delegatecalls. The contract is abstract, hinting that it could be configured for specific deployments. In the architecture, this controller serves as the bridge between the UFarm pool and the Uniswap V3 protocol, encapsulating all the necessary calls to the Uniswap V3 SwapRouter and NonfungiblePositionManager (NFPM). Its goals are to allow the pool to trade (rebalance or swap assets) and to provide or withdraw liquidity in Uniswap V3 pools to generate yield, all while enforcing UFarm’s security constraints.

**Swap Logic (Exact Input Swaps):** The controller provides two swap functions, analogous to Uniswap V3’s `exactInputSingle` and `exactInput`:

* `delegatedSwapExactInputSingleHop(bytes _data)`: for a single-pool swap (one hop).
* `delegatedSwapExactInputMultiHop(bytes _data)`: for multi-hop swaps across multiple pools (routing through intermediate tokens).

Both are `external` and tagged with `checkDelegateCall nonReentrant`, meaning they must be called by the pool via delegatecall.

For the single hop swap, `_data` is expected to be the encoded `ISwapRouter.ExactInputSingleParams` struct (the same struct Uniswap’s router uses). The controller decodes it into `params`, which includes: `tokenIn`, `tokenOut`, `fee` (the Uniswap pool fee tier), `recipient`, `deadline`, `amountIn`, `amountOutMinimum`, and possibly `sqrtPriceLimitX96`. Immediately, it **checks that `params.recipient` is the pool (address(this))**, reverting with `INVALID_RECIPIENT()` if not. This ensures the swap’s output stays in the pool. It then stores `tokenIn`, `tokenOut`, and `amountIn` from the params and verifies that `tokenOut` is allowed by the pool’s whitelist. (Interestingly, it does not explicitly check `tokenIn` here, under the assumption that `tokenIn` is currently held by the pool; still, `tokenIn` would normally also be an allowed token or it wouldn’t be in the pool to begin with.) After approval check, it calls `SafeOPS._forceApprove(tokenIn, swapRouter, amountIn)` to approve the Uniswap V3 SwapRouter to pull the tokens. Then it calls `ISwapRouter(swapRouter).exactInputSingle(params)` which executes the swap on Uniswap V3, returning the amount of `tokenOut` obtained. The router handles all the heavy logic of finding the pool by fee and swapping. The controller then emits `SwapUnoV3(tokenIn, tokenOut, amountIn, amountOut, PROTOCOL())`. This event logs the swap details similar to the V2 case.

For multi-hop swaps, the Uniswap V3 router uses a single call `exactInput(ExactInputParams)` where the `params.path` is a packed sequence of hops (tokenA, fee, tokenB, fee, tokenC, ...). However, Solidity can’t directly decode a struct with a bytes array easily in an external call. So the controller manually decodes the expected parameters. `_data` is decoded as `(address _recipient, uint256 _deadline, uint256 amountIn, uint256 amountOutMin, bytes _path)`. This corresponds conceptually to Uniswap’s ExactInputParams (though that struct is `(bytes path, address recipient, uint256 deadline, uint256 amountIn, uint256 amountOutMinimum)`, they pulled out the fields differently to decode easily). After decoding, it ensures the `_recipient` equals the pool (address(this)) just as before, by not allowing any other recipient (this check is done implicitly later by setting recipient to address(this) in the struct, but also they verify tokens in path belong to allowed set for pool). It then sets up to validate the path. The `_path` bytes encodes the sequence of swaps. The controller needs to ensure that every output token along the path is allowed. It does this by iterating through the path in an assembly block. They load the first token (tokenIn) from the path (20 bytes) via assembly. Then starting from the second token, they loop: the path format is \[tokenIn(20 bytes) | fee(3 bytes) | token1(20 bytes) | fee(3 bytes) | token2(20 bytes) | ... tokenN (last 20 bytes)]. The loop index `i` starts at 43, which corresponds to the offset of the first token after tokenIn in this encoding (20+3+20 = 43, which is the start of token1 or token2? Actually tokenIn (20) + fee (3) = 23, token1 starts at byte 23, but due to how bytes are aligned in memory, the code likely accounts for the memory layout). In each iteration, they load a 20-byte chunk from the path at position `i` into `tokenOut`. This effectively extracts each subsequent token address in the path. For each such tokenOut, they check `if (!pool.isTokenAllowed(tokenOut)) revert TokenIsNotAllowed(tokenOut)`. The loop increments `i` by 23 each time (which skips over the next 20-byte token address and 3-byte fee to the following token). This ensures every intermediary token and the final token are whitelisted. By the end of the loop, `tokenOut` will contain the last token in the path (the final output token). They also have preserved the first token as `tokenIn` from earlier.

After validation, it constructs the Uniswap router’s `ExactInputParams` struct in memory with `path: _path, recipient: address(this), deadline: _deadline, amountIn: amountIn, amountOutMinimum: amountOutMin`. Then it approves the SwapRouter to spend `amountIn` of `tokenIn` (with SafeOPS), and calls `swapRouter.exactInput(params)`. This will execute the multi-hop swap. The return is the amount of final token actually received (the router returns amountOut). They assign that to `amountOut`. Finally, they emit `SwapUnoV3(tokenIn, tokenOut, amountIn, amountOut, PROTOCOL())`, logging the swap.

These swap functions thus cover the trading aspect for one or multiple hops, with checks on allowed tokens and correct recipient enforcement. It’s simpler than the V2 case because it leverages Uniswap’s router for actual execution, instead of manually interacting with each pool (since Uniswap V3 swaps aren’t trivial to implement without the router due to price range logic).

**Liquidity Position Management:** Uniswap V3 liquidity is represented by NFTs managed by the NonfungiblePositionManager (NFPM). The controller provides several functions to manage these:

* `delegateMintNewPosition(bytes _data)`: Allows the pool to create (mint) a new liquidity position in a Uniswap V3 pool. The `_data` is decoded as `INonfungiblePositionManager.MintParams`, which includes: token0, token1, fee (pool fee tier), tickLower, tickUpper (price range bounds), amount0Desired, amount1Desired, amount0Min, amount1Min, and recipient. The controller first ensures both token0 and token1 are allowed by the pool’s whitelist. It then enforces a ordering: Uniswap V3 positions also expect token0 < token1 by address. If `token0 > token1`, it swaps them and also swaps the corresponding amounts and mins in the params struct to match the flip. This is crucial so that the NFPM doesn’t revert (it expects the lower-address token as token0). Next, it checks the `mintParams.recipient`. If it’s not the pool, it sets it to `address(this)` – effectively forcing the recipient of the NFT to be the pool itself (so the pool will own the liquidity token). The pool should own the position since it’s part of the pool’s assets. Then, it prepares the token allowances. The NFPM contract will withdraw the required tokens from the caller (pool) to create liquidity. The controller uses `SafeOPS._forceApprove` to approve NFPM for `amount0Desired` of token0 and `amount1Desired` of token1. After approvals, it calls `nfpm.mint(mintParams)`. The NFPM returns a tuple: `(tokenId, liquidity, amount0, amount1)`. `tokenId` is the NFT identifier of the newly created position, `liquidity` is the actual liquidity added (in liquidity units), and `amount0` and `amount1` are the amounts of tokens actually used (which could be less than desired if one side was not fully needed to match the price ratio). The controller then does a cleanup: if less than the full desired amounts were used (`amount0 < amount0Desired` or `amount1 < amount1Desired`), it sets the allowance of the NFPM for that token back to 0. This avoids leaving an infinite or large allowance hanging, and frees the unused tokens in the pool. Finally, it emits a `PositionMintedUnoV3` event with details of the position. The event includes token0, token1, the NFPM address, fee tier, tickLower, tickUpper, the liquidity minted, the tokenId of the NFT, and the amounts of token0 and token1 used. This is a comprehensive log of the new position.

* `delegateIncreaseLiquidity(bytes _data)`: Adds more liquidity to an existing position. It decodes `IncreaseLiquidityParams` (tokenId, amount0Desired, amount1Desired, amount0Min, amount1Min, deadline). It first calls `_checkOwnershipOfPosition(tokenId)` to ensure the pool (as the caller) actually owns this NFT (likely by checking NFPM.ownerOf(tokenId) == address(this)). Then it fetches the current position data with `_getPositionData(tokenId)` which returns a struct containing the position’s details including token0, token1, current liquidity, etc.. It then performs whitelist checks: both token0 and token1 of that position must still be allowed in the pool. (If the pool decided to disallow a token that is in an existing position, this check would stop adding more of it.) Next, it approves NFPM to pull the additional amounts: calls SafeOPS.\_forceApprove for token0 and token1 with the respective desired amounts. Then it calls `nfpm.increaseLiquidity(incLiqParams)`. The result is `(liquidityIncreased, amount0In, amount1In)` – how much liquidity was added and how many tokens were actually spent. It clears any leftover allowance if less than desired was used (similar to mint). Finally, it emits `PositionIncreasedUnoV3(token0, token1, nfpmAddress, tokenId, liquidityIncreased, amount0In, amount1In, PROTOCOL())`. This logs the addition.

* `delegatedDecreaseLiquidity(bytes _data)`: Removes some liquidity from a position without closing it entirely. It decodes `DecreaseLiquidityParams` (tokenId, liquidity, amount0Min, amount1Min, deadline). It fetches position info and a target address via `_getTarget()` (similar to the V2 removal, this could determine if proceeds go to the pool or an end user). Then it calls an internal `_decreaseLiquidity(posInfo, decLiqParams, _target, _withdrawalHash, collectAll=false)`. The logic of `_decreaseLiquidity` isn’t shown in the snippet, but we can infer it likely calls NFPM.decreaseLiquidity and NFPM.collect on the position. It probably burns the specified liquidity and withdraws the corresponding amount0 and amount1 from the position. If `_target` is the pool or user, it would pass that as the recipient for collected tokens. The `amount0Min` and `amount1Min` ensure it doesn’t withdraw less than expected. Since `collectAll` is false in this case, it might mean “do not collect outstanding fees, only withdraw liquidity”. This function likely emits events for withdrawals if \_target is not the pool, similar to how V2 did.

* `delegateBurnPosition(bytes _data)`: This closes a position entirely. It actually uses the DecreaseLiquidityParams as well, but in code they treat it slightly differently. The function decodes DecreaseLiquidityParams into `burnParams`, calls `_checkOwnershipOfPosition(tokenId)`, and retrieves `posInfo = _getPositionData(tokenId)`. It then sets `burnParams.liquidity = posInfo.liquidity` (meaning remove all liquidity). It gets `_target` and `_withdrawalHash`. If `posInfo.liquidity > 0`, it calls `_decreaseLiquidity(posInfo, burnParams, _target, _withdrawalHash, collectAll=true)`. Here `collectAll=true` likely signals that after removing liquidity it should also collect any fees in the position. After that, it calls `nfpm.burn(tokenId)` to actually burn the NFT (removing it from existence). If \_target was a user, presumably `_decreaseLiquidity` would have sent the tokens to them (with events). After burning, it emits `PositionBurnedUnoV3(nfpmAddress, tokenId, PROTOCOL())` to indicate that the NFT was burned.

* `delegatedCollectAllFees(bytes _data)`: Though not explicitly detailed above, the partial withdrawal logic references this. It likely takes a `CollectParams` (tokenId, recipient, amount0Max, amount1Max) to collect all accrued fees from a position and send to the pool (address(this) as recipient). This would convert the position’s earned fees into actual tokens held by the pool. That function probably does not require delegatecall (or maybe it should) because it’s part of multi-tx withdraw flow. But likely it’s similar: check ownership, then call nfpm.collect.

All these functions ensure that whenever tokens (either as swap output or liquidity withdrawal) come to the pool or leave the pool, they are governed properly. The usage of `_getTarget()` in removal functions indicates a design where if a user is withdrawing from the pool, the pool might set a target (the user’s address) so that the controller can send tokens directly out to the user, bypassing keeping them in the pool. This is an efficiency to avoid an extra transfer.

**Delegatecall and Usage:** As with the other controllers, UnoswapV3Controller’s functions are meant for delegatecall. The function signatures explicitly require it. When the pool wants to manage a Uniswap V3 position or do a swap, it will delegatecall into these functions. During those calls, `address(this)` is the pool, and the controller’s code uses the `swapRouter` and `nfpm` addresses (which are set in the controller’s constructor as immutables). Provided the immutables are correctly handled, the code will call out to the actual Uniswap V3 contracts. The pool’s tokens are used (since transfers from `address(this)` in context are from the pool). The NFT positions themselves (tokenIds) will be held by the pool’s address on-chain. This means the pool’s address is the owner of any minted liquidity NFT.

**Security Mechanisms:** The UnoswapV3Controller incorporates multiple layers of security similar to prior controllers, tailored to NFT positions:

* **Allowed Tokens Only:** Before executing swaps, it checks the final output token (and all intermediate tokens in multi-hop) against the pool’s whitelist. For liquidity, it checks that both tokens of a position are allowed whenever adding or interacting with that position. This prevents the pool from unintentionally holding disallowed assets via a Uniswap V3 position or swap.
* **Recipient Enforcement:** It forces all swap outputs and collected liquidity to go to the pool (or a designated target set by the pool). For swaps, this is done by requiring `params.recipient == address(this)` or setting it explicitly. For minting, it overrides `mintParams.recipient` to the pool itself so the NFT is owned by the pool. For collecting or withdrawing, using `_target` logic ensures if it’s an internal operation the tokens go to pool, or if it’s a user withdrawal, the target is explicitly set by pool code – not an arbitrary address passed in.
* **Ownership Checks:** Any operation on a position (increase, decrease, collect, burn) first verifies the pool owns that `tokenId` via `_checkOwnershipOfPosition`. This stops any attempt to manipulate someone else’s NFT or a non-existent one.
* **Reentrancy Guard:** All external functions are `nonReentrant`, preventing a malicious token or callback from re-entering pool functions while one is in progress.
* **External Call Safety:** The controller uses SafeOPS for approvals to interact with the SwapRouter and NFPM safely. By tightly scoping allowances and clearing them, it reduces risk of leftover approvals. The actual calls to Uniswap’s router and NFPM are trusted external calls (Uniswap contracts are battle-tested), but any failure there would revert the transaction anyway. The controller sets reasonable parameters (e.g., uses the `amountOutMinimum` and `amount{0,1}Min` provided by the pool or user to ensure slippage is acceptable).
* **Use of Oracle/TWAP:** The code includes a function to fetch a TWAP (time-weighted average price) from a Uniswap V3 pool for a given period (`getTWAPsqrt`). Although not explicitly used in the swap or liquidity functions we traced, this indicates the controller (or subclass) might use TWAPs to make decisions, like ensuring the price hasn’t moved too much or valuing positions. A constant `TWAP_PERIOD()` is defined (likely to be overridden by a concrete implementation). This suggests a security measure against price manipulation: before adding or removing liquidity, the pool might check the TWAP price to avoid performing actions at a skewed instantaneous price. Even if not directly in the shown code, the presence of a price oracle address and TWAP logic hints that UFarm might incorporate price safety checks (perhaps in the `quoteOptimalLiquidityAmount` or elsewhere).
* **Partial Withdrawals and Fee Collection:** The controller provides an `encodePartialWithdrawalERC721` function which calculates how to withdraw a proportion of an NFT position. It decides whether to just collect fees or also decrease liquidity or burn, depending on the fraction. This shows that the architecture anticipates controlled exit of positions. It even generates the sequence of calls (collect fees, then maybe burn) as an array of transactions, ensuring that even complex withdrawal of NFT positions can be done systematically and safely.
* **Events:** There are events for swaps (`SwapUnoV3`) and for position changes: `PositionMintedUnoV3`, `PositionIncreasedUnoV3`, `PositionDecreasedUnoV3` (likely emitted inside `_decreaseLiquidity` or after collecting), `PositionBurnedUnoV3`, etc. These provide transparency and traceability of all Uniswap V3 related operations the pool performs.

Overall, the UnoswapV3Controller is carefully designed to manage the added complexity of Uniswap V3. By enforcing whitelist tokens and controlling ownership of liquidity NFTs, it keeps the pool’s exposure in check. It integrates Uniswap’s own safety parameters (min amounts, deadlines) to protect against slippage and time risk. Delegatecall ensures the pool’s balances and NFT ownership are directly manipulated by these operations, which avoids having to transfer assets to an external contract (except the well-known Uniswap contracts). The combination of these controllers (V2 and V3) means the UFarm pool can engage in sophisticated yield farming and trading strategies across different AMM types, all while the core logic remains modular and upgradeable. Each controller operates within the boundaries set by UFarm’s governance (whitelisted tokens, allowed protocols) and standard security best practices.

## Conclusion

**Relationships Summary:** In the UFarm architecture, **UFarmCore** is the hub that coordinates deployment (via factories) and enforces global rules (whitelists, permissions, pause, fees). **UFarmFund** contracts represent fund managers’ domain, each owning multiple **UFarmPool** vaults. Each Pool has an associated **PoolAdmin** for governance, and they rely on the **PriceOracle** for asset valuations. Pools engage with external DeFi through whitelisted **Protocol Controllers**, ensuring only vetted strategies execute (unless special permission for arbitrary controllers is granted). This modular design (core, factories, fund, pool, admin, oracle, controllers) allows flexibility (upgradeable proxies for core/fund/pool, dynamic strategy integration) while maintaining security boundaries (core-approved assets and code, per-fund permissions, and robust checks around state changes). The figure and descriptions above provide a comprehensive view of how these contracts work together to implement the UFarm decentralized fund management and investment platform.
